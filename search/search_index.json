{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#the-heal-platform","title":"The HEAL Platform","text":"<p>The HEAL Platform is a cloud-based and multifunctional web interface that provides a secure environment for discovery and analysis of NIH HEAL results and data. It is designed to serve users with a variety of objectives, backgrounds, and specialties.</p> <p>The HEAL Platform represents a dynamic Data Ecosystem that aggregates and presents data from multiple resources to make data discovery and access easy for users.</p> <p>The platform provides a way to search and query over study metadata and diverse data types, generated by different projects and organizations and stored across multiple secure repositories.</p> <p>The HEAL Platform also offers a secure and cost-effective cloud-computing environment for data analysis, empowering collaborative research and development of new analytical tools. New workflows and results of analyses can be shared with the HEAL community to enable collaborative, high-impact publications that address the opioid crisis.</p> <p>The HEAL Platform is powered by the open-source software \u201cGen3\u201d . Gen3 was created by and is actively developed at the University of Chicago\u2019s Center for Translational Data Science (CTDS) with the aim of creating interoperable cloud-based data resources for the scientific research community.</p> <p>Powered by </p> <p>Watch the introduction video to the HEAL Platform below</p> <p></p> <p>If your Browser does not support watching this video, here's a link to the video instead.</p>"},{"location":"cedar-getting-started/","title":"CEDAR form: Getting Started","text":""},{"location":"cedar-getting-started/#cedar-form-getting-started","title":"CEDAR form: Getting Started","text":""},{"location":"cedar-getting-started/#getting-started-the-least-you-need-to-know","title":"Getting Started: The least you need to know","text":"<ul> <li>Remember to Save!</li> <li>You can collaborate to complete the form by sharing it</li> <li>Make sure you know which fields do and don't apply to your study --&gt; Read the \"Sections: Overview &amp; Context\" page (coming soon) before starting the form</li> <li>Detailed coverage for each field and response options are available in the \"CEDAR Fields - Details\" section (coming soon)</li> <li>Check out the FAQs document (coming soon) for questions and answers you may also be interested in!</li> </ul> <p>Read below for tech tips on finding, using, and sharing the CEDAR form.</p>"},{"location":"cedar-getting-started/#accessing-and-using-the-cedar-form","title":"Accessing and Using the CEDAR form","text":""},{"location":"cedar-getting-started/#where-to-find-it","title":"Where to find it","text":"<p>Log in to cedar.metadatacenter.org. Click \"Shared with me\" in the left panel (#1). Hover over the tiles to see the full study names and find the right form (#2). Note: The file will not be in any of the folders (red X). </p> <p></p>"},{"location":"cedar-getting-started/#i-cant-find-my-form","title":"I can't find my form!","text":"<p>Step 1: Are you the person who registered the study?  </p> <p>Yes, I registered the study: Skip to Step 2.  </p> <p>No, someone else registered the study: The CEDAR form is initially available to whoever registered the study. However, it can be shared. The person who registered the study can share it with you by following the instructions in this section. If that is not a solution, request that the form be shared with you at heal-support@datacommons.io (please CC a PI on your email if you are not a PI).  </p> <p>Step 2: On the Shared with Me page (#1), turn off any filters by clicking Reset All (#2) if you see it there. Your study form may appear after resetting filters to the default.</p> <p></p> <p>If neither of these steps resolves your access to the CEDAR form, please reach out to heal-support@datacommons.io for assistance. </p>"},{"location":"cedar-getting-started/#collapse-and-expand-sections","title":"Collapse and expand sections","text":"<p>By default, the CEDAR forms open in \"expanded\" format, with all metadata sections and fields visible. Section headings are in green text, and metadata fields are in black.  </p> <p>You can collapse or expand a section by clicking on the green section heading. </p> <p></p> <p>Consider \"collapsing\" all sections when you open the form, and expanding them individually as you move through the form.</p>"},{"location":"cedar-getting-started/#save","title":"Save","text":"<p>The form does NOT autosave. Please be sure to save your entries by scrolling to the bottom of your form and clicking the green \u201cSave\u201d button at bottom right of the form. Saving will not close the page or redirect you.  </p> <p></p> <p>Save often while completing the form so you do not lose any entered metadata. Consider saving each time you complete a form section (or more often).  </p> <p>Be aware that the window will automatically log out after a certain period of inactivity, and it will NOT auto-save. Be sure to save before you switch tasks or step away from your computer.  </p>"},{"location":"cedar-getting-started/#sharing-with-collaborators","title":"Sharing with collaborators","text":"<p>The person who completed registration of the study on the HEAL Data Platform will be given access to the study's CEDAR form; however, multiple team members can collaborate on a form. The person who registered the study will be able to share access with other team members.</p> <p>To provide team members access to a CEDAR form:</p> <ul> <li>First: Each team member needs a CEDAR account.</li> <li>To create an account, visit cedar.metadatacenter.org.</li> <li>Click \"Register\" below the Password line.</li> <li> <p>Enter your first name, last name, a functional email address (that you can click on a verification email for), and a password.</p> </li> <li> <p>The person who registered the study can share the study's CEDAR form with other team members.</p> </li> <li>Find the CEDAR form by logging in to cedar.metadatacenter.org/, then clicking \"Shared with me\" (#1). Hover over the tiles to see the full study names and find the right form.</li> <li> <p>Click on the vertical three dots in the right corner of the tile for the CEDAR form (#2), then click on \"Share\" (#3).  </p> <p></p> </li> <li> <p>In the pop-up window, under \"With People,\" start typing the collaborator's name (#4). Select their name from the list below (#5)</p> <p></p> </li> <li> <p>Use the dropdown on the right (#6) to select \"can write\" (#7) if you want the collaborator to make edits, or \"can read\" for collaborators who will only review, not edit. Then click the OK button (#8).</p> <p></p> </li> <li> <p>You will see the collaborator's name appear on the right side of the window (red circle). Click Done (#9) to close the window and save changes.</p> <p></p> </li> <li> <p>You can remove access from collaborators who have left the team by clicking on the X on the right side of the window.  </p> </li> </ul>"},{"location":"cedar-getting-started/#help-text-tooltips","title":"Help text &amp; tooltips","text":"<p>Help text for each field is available while interacting with the field. Once you click into a field, a \"?\" icon is available in the upper right of the field area. Mouse over the \"?\" icon to view help text for that field.</p> <p></p>"},{"location":"cedar-getting-started/#how-to-select-or-remove-a-response-for-a-field","title":"How to select or remove a response for a field","text":"<p>Most fields on the CEDAR form have a drop-down panel of options.  </p> <p>Click in the field to interact with the response options. You may then click to open the drop-down list of responses. Click on a response to select it for the CEDAR field.  </p> <p></p> <p>If the response field says \"Select options\" instead of \"Select option,\" you may choose multiple responses for a field; simply click all options in the drop-down that apply.  </p> <p></p> <p>To remove a response that has been selected, click in the dropdown to select a new response. Or, for fields that allow multiple responses, click the X to the right of the </p> <p></p> <p>Jump to Sections: Overview &amp; Context page (coming soon)</p> <p>Jump to CEDAR Fields - Details page (coming soon)</p> <p>Jump to FAQs (coming soon)</p>"},{"location":"contact/","title":"Contact","text":""},{"location":"contact/#contact","title":"Contact","text":"<p>Need help? Please contact our help desk.</p> <p>Powered by </p>"},{"location":"data_mgmt_and_repos/","title":"Data Management and Repositories","text":""},{"location":"data_mgmt_and_repos/#data-management-and-repositories","title":"Data Management and Repositories","text":"<p>To help HEAL investigators in the repository selection process, the HEAL Data Stewards at RENCI/RTI have developed Repository Selection Criteria and identified a number of recommended repositories. A HEAL-compliant repository is a FAIR data repository that is NIH-supported and ideally has an API for metadata and data permissions calls.</p> <p>The following is a non-exhaustive selection of repositories and resources currently made accessible through or leveraged by the Heal Platform:</p> <p> </p> Representation of Data Resources on the HEAL Data Platform. <p>Studies from different Data Resources can be filtered and selected on the Discovery Page in the Study Filters section (top panel):</p> <p> </p> Studies can be filtered by Data Resource using their respective tags. <p>For more information from NIH regarding public access and data sharing, visit https://heal.nih.gov/about/public-access-data.</p>"},{"location":"downloading_files/","title":"Data File Downloads","text":""},{"location":"downloading_files/#data-file-downloads","title":"Data File Downloads","text":"<p>Users can download data files associated with a study by downloading the files directly from the Discovery page, or leveraging the CTDS-owned python software development kit (SDK) and the tool \u201cGen3-client\u201d if the file size exceeds 250 MB.</p> <p>Note that current studies that have datasets of more than 250 MB are those with the following project numbers: a) cdcwonder and b) deaarcos1.</p> <p>Note, that accessing data files requires linked access to all FAIR enabled repositories, as described here. A pop-up window will remind users:</p> <p></p> <p>Users are reminded to link the account to all other FAIR enabled repositories, as described here.</p>"},{"location":"downloading_files/#download-data-files-from-the-discovery-page","title":"Download Data Files from the Discovery Page","text":"<p>Users can download data files up to sizes of 250 MB directly from the Discovery Page.  </p> <p>Below you find the simple steps to do so.</p> <ol> <li> <p>Navigate to the Discovery Page. Link your accounts to FAIR repositories as described here.  </p> </li> <li> <p>Find the study of interest by using the search features or the list of accessible studies.  </p> </li> <li> <p>Select the clickable box next to the study.     Click on \"Download ZIP\", which will initiate the data download. </p> <p>Select the study and click \"Download ZIP\".</p> </li> <li> <p>Users will be prompted with a window that shows the download is being prepared.     Please do not navigate away from this page until the download is complete. </p> <p>After clicking \"Download ZIP\", your download is being prepared. Please do not navigate away from this page until the download is complete.</p> </li> <li> <p>Users will be notified once the download is ready. If the download doesn't start automatically, please follow the link prompted. </p> <p>Users will be notified once the download is ready. Save the file(s) by selecting the directory using the prompted window.</p> </li> <li> <p>If the file size exceeds 250 MB, users will be notified to deselect studies to reduce the size or use other tools: </p> <p>Users are advised to use other tools to download the files if the total file size exceeds 250 MB. Please see the next section for a step-by-step guide using these tools.</p> </li> </ol>"},{"location":"downloading_files/#download-data-files-using-the-gen3-client","title":"Download Data Files using the Gen3-client","text":"<p>In order to download data files above 250 MB, users will need to utilize the Gen3-client command line tool developed by the University of Chicago\u2019s Center for Translational Data Science.</p> <p>The current studies that have datasets of more than 250 MB are those with the following project numbers: a) cdcwonder and b) deaarcos1.</p> <p>Find below a guide to download data files using the Gen3-client:</p> <ol> <li> <p>Log in to the HEAL Platform at https://healdata.org/portal/login. Link your accounts to FAIR repositories as described here.  </p> </li> <li> <p>Find and select one or multiple studies of interest on the Discovery Page. For multiple studies, select \"Data Availability\" in the top right corner, click \u201cAvailable\u201d, and choose multiple studies.</p> </li> <li> <p>Click on the button \u201cDownload Manifest\".</p> </li> </ol> <p></p> <p>Select a study of interest, then click on the button \u201cDownload Manifest\".</p> <ol> <li>Create and download an API key from your Profile Page. Note where you save the API key on your local machine.  </li> </ol> <p></p> <p>Create an API key on the profile page.</p> <p></p> <p>Download the API key as json file and note the directory where the API key was saved for step 6.</p> <ol> <li> <p>Download and configure the Gen3-client     a. Follow the download instructions of the Gen3-client here. The client can be downloaded here.  </p> <p>b. In your terminal, configure your profile using the following command:  </p> <pre><code>gen3-client configure --profile=&lt;profile_name&gt; --cred=&lt;credentials.json&gt; --apiendpoint=&lt;api_endpoint_url&gt;`\n</code></pre> <p>Mac/Linux:   </p> <pre><code>gen3-client configure --profile=demo   --cred=~/Downloads/demo-credentials.json --apiendpoint=https://healdata.org/\n</code></pre> <p>Windows:   </p> <pre><code>gen3-client configure --profile=demo   --cred=C:\\Users\\demo\\Downloads\\demo-credentials.json --apiendpoint=https://healdata.org/\n</code></pre> <p>If the command was succesful, you should get the following output:</p> <p><code>10:08:20 Profile 'demo' has been configured successfully.</code></p> <p>If successfully executed, a configuration file will be stored under the directory the user specified under \u201ccred\u201d. For troubleshooting, refer to the instructions found here.  </p> <p>c. Download files by using the following command, which references the manifest file name and its location:  </p> <p></p><pre><code>gen3-client download-multiple --profile=&lt;profile_name&gt; --manifest=&lt;manifest_file&gt; --download-path=&lt;path_for_files&gt;\n</code></pre> For example: <pre><code>gen3-client download-multiple --profile=demo --manifest=manifest.json --download-path=downloads\n</code></pre> <pre><code>2021/06/03 16:48:46 Reading manifest...   200 B / 200 B [===================] 100.00% 0s  \nWARNING: flag \"rename\" was set to false in \"original\" mode, duplicated files under \"downloads/\" will be overwritten   \nProceed? [y/n]:\n</code></pre> <p>Enter:</p> <pre><code>y\n</code></pre> <p>Output:</p> <pre><code>2021/06/03 16:48:47 Total number of GUIDs: 1   2021/06/03 16:48:47 Preparing file info for each file, please wait...   1 / 1 [============================================] 100.00% 0s   2021/06/03 16:48:47 File info prepared successfully   arcos_all_washpost.tsv.gz 6.41 GiB / 6.41 GiB [=======================================================] 100.00% 0s\n</code></pre> </li> </ol>"},{"location":"downloading_files/#download-data-files-in-workspaces-using-the-python-sdk","title":"Download Data Files in Workspaces using the Python SDK","text":"<p>Users can download data files to the workspaces by leveraging the CTDS-owned python software development kit (SDK). Follow instructions below.</p> <ol> <li> <p>Log in to the Data Commons at https://healdata.org/portal/login. Link your accounts to FAIR repositories as described here.  </p> </li> <li> <p>Find and select one or multiple studies of interest on the Discovery Page. Select \"Data Availability\" in the top right corner and click on \u201cAvailable\u201d to see all available studies.  </p> </li> <li> <p>Select a study and click on \"Open in Workspace\". </p> </li> <li> <p>Select a workspace VM and click \"Launch\". Choose the \"(Generic) Jupyter Notebook with R kernel\" if you are familiar with setting up Python- or R-based Notebooks, or if you just exported one or multiple studies from the Discovery Page and want to start your custom analysis. Choose a VM with the name of the Notebook if you selected the studies relevant to a specific Notebook and want to work on the Notebook in interactive mode. </p> <p>Available workspaces on the HEAL Platform (top). Users need to link accounts from other repositories (bottom; click here to see how).</p> </li> <li> <p>Find all files under /data/healdata.org/ with the ending \"PLACEHOLDER\". These files can be directly downloaded either in the terminal or in a notebook cell. </p> </li> <li> <p>Click on one file and copy the command and GUID. </p> </li> <li> <p>Open a new terminal under \"New\".  </p> </li> <li> <ul> <li>Type in the following command to download the file to the terminal: <pre><code>gen3 drs-pull object \"guid\"\n</code></pre></li> </ul> <p> </p> <ul> <li>If you are working in a notebook, type in the following command into a code cell to download the file:  </li> </ul> <p><code>!gen3 drs-pull object \"guid\"</code> </p> <p> </p> <ul> <li> <p>If you use the R kernel, change the command into <code>system(\"gen3 drs-pull object 'guid'\")</code> </p> </li> <li> <p>Note, that you can also use the manifest.json to download in batches, see below: </p> <p>Download files in batches with a file manifest using the commands shown above.</p> </li> </ul> </li> <li> <p>The file(s) should be downloaded and is ready to be worked with in your Notebook. </p> <p>Downloaded files can be found in your home directory.</p> </li> </ol>"},{"location":"faqs/","title":"FAQs","text":""},{"location":"faqs/#faqs","title":"FAQs","text":"<ol> <li> <p>What can I do on the HEAL Platform?  </p> <p>The HEAL Platform is a cloud-based and multifunctional web interface that provides a secure environment for discovery and analysis of HEAL results and data. Explore all functionalities here.  </p> </li> <li> <p>Which datasets are currently open-access?  </p> <p>Find all open-access datasets here.  </p> </li> <li> <p>Where can I see individual study metadata?  </p> <p>Individual study metadata is shown upon clicking on a study entry on the Discovery Page. Click to read the full description here.  </p> </li> <li> <p>Do I need to store my data in a particular location to participate in the HEAL platform?  </p> <p>You must store your data in a HEAL-compliant repository. A HEAL-compliant repository is a data repository that is NIH-supported and ideally has an API for metadata and data permissions calls. To help HEAL investigators in the repository selection process, the HEAL Data Stewards at RENCI/RTI have developed Repository Selection Criteria and identified a number of recommended repositories. If you have questions regarding costs associated with data storage in HEAL-compliant repositories, please contact the HEAL Data Stewards.</p> </li> <li> <p>How and where can I see if I have access to a study?  </p> <p>Clicking on an individual study on the Discovery Page will show in the top right corner if they are accessible to the user. To see all studies users have access to, users should navigate to the Discovery Page and select \u201cData Availability\u201d - Available\u201d. More information here.       </p> </li> <li> <p>I do not have access to a specific study, how can I get access?  </p> <p>RENCI/RTI (Renaissance Computing Institute) at the University of North Carolina at Chapel Hill establishes and manages data access contacts over all data contributors/sources. To request access to controlled data, users should contact RENCI/RTI at HEALstewards@renci.org.  </p> </li> <li> <p>The profile page says I have access but I don\u2019t see it on the Discovery Page.  </p> <p>Please contact our help desk.  </p> </li> <li> <p>I would like to download data files from a specific study, what do I need to do?  </p> <p>Users can download the studies directly from the Discovery Page as described here, or, if the file size exceeds 250 MB, users need to use the Gen3-client command line tool to download data files, as described here. Additional information on the Gen3-client may be found here.  </p> </li> <li> <p>How can I get data files into the Workspace from the Discovery Page?</p> <p>Click here to follow the steps on how to get files from the Discovery Page to the Workspace.  </p> </li> <li> <p>How do I find a study?  </p> <p>Click here to see possible ways to search for a study on the Discovery Page.  </p> </li> <li> <p>Can I download files directly from the portal?</p> <p>Yes, you can. Click here to follow the steps to download data files from the Discovery Page. Caution: the download is limited to file sizes of 250 MB.    </p> </li> <li> <p>My download is not working.  </p> <p>Please check if your file size exceeds 250 MB. If yes, please other tools as described here to download the files. Note that the current studies that have datasets of more than 250 MB are those with the following project numbers: a) cdcwonder and b) deaarcos1. If errors persist, please contact the help desk.  </p> </li> <li> <p>My data file download using the Gen3-client gets stuck, where can I get help?  </p> <p>For troubleshooting, please see the Gen3-client documentation here. If errors persist, contact our help desk.  </p> </li> <li> <p>The Gen3-client shows errors, where can I get help?  </p> <p>To check that the client is working and to confirm the client version, type \u2018gen3-client\u2019 in the terminal. Typing \u2018gen3-client help\u2019 will display the help menu. Users must provide the full path of the tool in order for the commands to run, for example, \u2018./gen3-client\u2019 while working from the directory containing the client. For more troubleshooting, please see the Gen3-client documentation here. If errors persist, contact our help desk.  </p> </li> <li> <p>I want to work interactively on the Tutorial Notebooks. Show me how.  </p> <p>Click here to follow the steps of a demo.  </p> </li> <li> <p>What are the current Tutorial Notebooks?  </p> <p>Click here to see a list of currently available Notebooks in Python and R.  </p> </li> <li> <p>How do I work with these Tutorial Notebooks?  </p> <p>Click here to see a guide of how to work with the Tutorial Notebooks.  </p> </li> <li> <p>How do I link my account to a FAIR enabled repository?  </p> <p>Click here to see how to link your account to a FAIR enabled repository.  </p> </li> <li> <p>What do the Workspaces have to offer?  </p> <p>Click here to see how to get started and here to see what languages, tools, and environments the workspaces have enabled.  </p> </li> <li> <p>I want to report a bug!  </p> <p>Please report any errors or bugs to our help desk.  </p> </li> </ol>"},{"location":"hosted_data_types/","title":"Types of Hosted Data","text":""},{"location":"hosted_data_types/#types-of-hosted-data","title":"Types of Hosted Data","text":"<p>As part of the NIH HEAL Initiative, the HEAL Platform aims to transform opioid research into a virtual, annotated, searchable catalog where data from different studies can be analyzed, compared, and combined.</p> <p>The data presented on the HEAL Platform are diverse and include scientific research across multiple disciplines. For example, researchers can use this single platform to find clinical patient care data and public records as well as \u201c-omics\u201d data files with associated sample collection and processing data.</p> <p>The HEAL platform aims to make data more accessible by following the \"FAIR\" principles:</p> <p>Findable</p> <ul> <li>Researchers are provided an intuitive interface to search over metadata for HEAL studies and related datasets.</li> <li>Each study and dataset will be assigned a unique, persistent identifier.</li> </ul> <p>Accessible</p> <ul> <li>Authenticated users can request and receive access to controlled-access data by data providers.</li> <li>Metadata can be accessed via an open API.</li> </ul> <p>Interoperable</p> <ul> <li>Standard metadata vocabularies facilitate discovery and joint analysis of HEAL and related datasets. Data can</li> <li>Data can be easily exported to various workspaces for analysis using a variety of software tools.</li> </ul> <p>Reusable</p> <ul> <li>Data can be easily reused to facilitate reproducibility of results, development and sharing of new tools, and collaboration between investigators.</li> </ul> <p>FAIR data repositories are traditionally a part of a larger institution established for research, data archiving, and, to serve data users of that organization.</p>"},{"location":"logging-in/","title":"Logging In","text":""},{"location":"logging-in/#logging-in-to-the-platform","title":"Logging In to the Platform","text":"<p>You will not need to log in in order to:</p> <ul> <li>browse the study metadata on the Discovery Page</li> <li>read the pre-made tutorial notebooks in the \u201cExample Analysis\u201d tab</li> </ul> <p>You will need to log in and obtain authorization (access) in order to:</p> <ul> <li>register your own study</li> <li>access studies with controlled data</li> <li>perform analyses in workspaces</li> <li>download data files and file manifests</li> <li>run interactive tutorial notebooks in workspaces</li> </ul> <p>Start by visiting the login page.</p> <p></p>"},{"location":"logging-in/#login-page-options","title":"Login Page Options","text":"<ul> <li>Login from Google: You may login using any Google account credentials, or a G-suite enabled institutional email. This option may or may not be available depending on the institution or organization the user is associated with. Users should contact the IT support to verify if this option is available. For staff, students, and faculty of the University of Chicago, more information can be found here.</li> <li>ORCID Login: Users with an ORCID account can log in using their ORCID credentials.</li> <li>InCommon Login: Users can login with a participating institution that is federated by InCommon. Click on \u201cSelect...\u201d to browse and choose the institution.</li> </ul> <p>After successfully logging in, your username will appear in the upper right-hand corner of the page.</p>"},{"location":"platform_discovery_page/","title":"Discovery Page","text":""},{"location":"platform_discovery_page/#discovery-page","title":"Discovery Page","text":"<p>The Discovery Page provides users a venue to search and find studies and datasets displayed in the HEAL Platform. Users can browse through the publicly accessible study-level metadata without requiring authorization.</p> <p>Use text-based search, faceted search, and tags to rapidly and efficiently find relevant studies, discover new datasets across multiple resources, and easily export selected data files to the analysis workspace.</p> <p></p> <p>The Discovery Page of the HEAL Platform. Browse through datasets and study-level metadata and find studies using tags or the free text search field.</p>"},{"location":"platform_discovery_page/#search-features","title":"Search Features","text":"<p>Different features such as free text search bar and tags on the Discovery Page help navigating and refining the search.</p> <ol> <li>Free Text Search: Finding studies is made easy using keywords in the free text-based search bar or using tags. The free-text search bar can be used to search for study title, investigator name, or any keyword that is mentioned in the metadata of the study except for Filter options (see #3 below).</li> <li>Data Repository: To filter studies by specific data repositories used by a study, click the Data Repository button (2A), which will reveal a Data Repository field (2B) in which you may select repositories of interest. If you select multiple repositories, it will use an \"OR\" logic to filter studies that have reported any of those repositories.  </li> <li>Filters: Click \"Filters\" to expand the options to filter studies by different study metadata tags. Find a range of metadata tags in five categories (Study Type, Data Type, Subject Type, Gender, and Age) to narrow down any search. Selecting multiple tags can work in either an \"AND\" a \"OR\" logic, depending on the selecion at the top of the Filters drawer. Click on \"Reset Filters\" to deselect all filters and start over.</li> <li>Total number of studies: Shows the number of studies the HEAL Platform is currently displaying that match the various search and filter criteria selected.</li> <li>Export Options: Login first to leverage the export options. Select one or multiple studies by checking the checkbox at the beginning of the study row and you can then: 1) download the attached data files (only available for some studies); 2) download a file manifest (especially useful for data files whose sizes exceed 250 MB); or 3) export the metadata and data files to secure cloud environment \"Workspaces\" to start your custom data analysis in Python, R, or Stata.</li> <li>Studies: This feature presents all current studies on the HEAL Platform. Click on any study to show useful information about the study (metadata). </li> <li>Data Availability: Filter on available, pending, and not-yet-available datasets.</li> <li>Documentation: This brings you to home page for the documentation (including this page you are currently on).</li> <li>Login Page: Login on the HEAL Platform to leverage all features. Read further here.</li> </ol>"},{"location":"platform_discovery_page/#study-page","title":"Study Page","text":"<p>You can view the study page by clicking on a study in the search results, which will open a drawer with the study page on the right.  </p> <p></p> <p>The study page defaults to open the Summary tab, but there are 4 tabs in the study page:</p> <ul> <li>Summary tab: Includes information about the study, with selected study-level metadata tags listed at the bottom (reflecting metadata reported in the CEDAR form). (Shown in figure above)</li> <li> <p>Data tab: Provides buttons to download variable-level metadata, study-level metadata, a manifest of the metadata files, or download all files. Note: you must be logged in to use some of these features.  This tab will also display a link to the data in the repository if it has been provided to the platform.  </p> <p></p> </li> <li> <p>Cite tab: Provides citation information for the study on the platform and for the study data in the repository</p> <p></p> </li> <li> <p>Related Studies tab: Shows other very-closely-related studies on the platform that share the same NIH serial number (read more about NIH serial numbers here). Most studies will not have any related studies listed.  </p> <p></p> </li> </ul>"},{"location":"platform_discovery_page/#find-available-study-level-metadata","title":"Find available Study-level Metadata","text":"<p>You can find available study-level metadata for a study on the HEAL Platform from the study page. There are two ways to see the metadata. </p> <ul> <li>The study page opens on the Summary tab, which includes information about the study with selected study-level metadata tags listed at the bottom (see figure in Study Page, above).  </li> <li>The Data tab on the study page includes a button to download study-level metadata (see Data tab figure, above).</li> </ul>"},{"location":"platform_discovery_page/#find-accessible-datasets","title":"Find accessible Datasets","text":"<p>On the Discovery page, users can filter for studies that have data available through the platform using the Data Availability filter in the right-most column of the search results. Click on Data Availability (#1), then select only the Available box (#2) to find data that is available and that you have access to through the platform, then click OK (#3). The Discovery Page will automatically update the list of studies that have available datasets.  </p> <p></p> <p>The filter allows you to check more than one availability status, and uses an \"OR\" logic to filter studies. To interpret the different availability status options, please see the next section.  </p>"},{"location":"platform_discovery_page/#data-availability-options","title":"Data Availability Options","text":"<p>Waiting: \u201cWaiting\u201d is the default data availability status for studies added to the platform. This status means:  </p> <ul> <li>Data have not yet been submitted to a repository; or, </li> <li>The repository has not yet released the data; or, </li> <li>The study team has not yet provided the link to the data to the HEAL Data Platform. (To submit a data link, see our documentation about this)</li> </ul> <p>Available: \u201cAvailable\u201d means you are now able to access these data via the HEAL Data Platform, by downloading them and/or by importing them in a workspace</p> <p>Request Access: \u201cRequest Access\u201d means that the data has been deposited in a repository and is available. To access the data, you will first need to visit the host repository to request access to it, following the repository\u2019s standard procedures. Once that is complete, authorized users can then bring these data into a HEAL workspace for analysis.</p> <p>Not Available: \u201cNot Available\u201d means that no data will be made available for this study.</p>"},{"location":"platform_discovery_page/#select-files-on-the-discovery-page-and-bring-them-to-the-workspace","title":"Select Files on the Discovery Page and bring them to the Workspace","text":"<p>The above gif shows the workflow used to select data files from the Discovery Page and bring them into the workspace using Jupyter Notebooks.  </p> <ol> <li> <p>Log in at https://healdata.org/portal/login. Link your account to all FAIR repositories as described here.  </p> </li> <li> <p>Find and select the study by the project number (in this example: 1U2CDA050098-01_a) on the Discovery Page. Find other current open-access studies here.  </p> </li> <li> <p>Click the \u201cOpen in Workspace\u201d button in the upper right corner. This step will create a manifest folder which you can find later in the Workspace\u2019s folder \"data/healdata.org\". </p> <p>Select the study and click on \u201cOpen in Workspace\u201d.</p> </li> <li> <p>Choose a workspace flavor and click \"Launch\". This step may take several minutes.  </p> </li> <li> <p>Navigate to the <code>/pd/data/healdata.org/</code> folder and find the placeholder files there. Click on those placeholder files to find instructions how to download the files or see below.  </p> </li> <li> <p>From the directory <code>/pd</code>, users can now start a new notebook. Click \u201cNew\u201d (upper right corner) or open a previously saved notebook on the landing drive to load the files into one of the cells, for example by running:</p> <p>! gen3 drs-pull object \"guid\"</p> <p>import pandas as pd   </p> <p>os.chdir('/pd')</p> <p>demo_df = pd.read_csv('pd/demo_file.txt', sep='\\t')</p> <p>demo_df.head()</p> </li> </ol> <p>More information for instructions on importing data can be found in the sections \"Download Files to Workspaces\" and \"Workspaces\".  </p> <ol> <li> <p>Make sure to terminate the workspace when the work is finished to reduce computational costs.</p> </li> <li> <p>\"pd\" means persistent directory. Saved files outside this directory will be lost.  </p> </li> <li>The manifest.json lists metadata of all exported files and can be used to download in batches </li> <li>Note, that all exported data files will be saved in the <code>/pd/data/healdata.org/</code> folder.  </li> <li>Please also note, that the workspace mounts up to a maximum of 5 different manifests while the workspace is running but shows only the latest exported manifest in a newly launched workspace.  </li> <li>Terminating the workspace will result in the loss of all but the latests manifest.  </li> </ol>"},{"location":"platform_example_analyses/","title":"Example Analysis Page","text":""},{"location":"platform_example_analyses/#example-analyses","title":"Example Analyses","text":"<p>The Example Analysis page contains a collection of view-only tutorial Jupyter Notebooks that provide demo analyses of datasets published on the HEAL platform.</p> <p>This tab acts as a 'visual table of contents\u2019 of available HEAL datasets.</p>"},{"location":"platform_example_analyses/#heal-example-analysis","title":"HEAL Example Analysis","text":"<p>This video introduces users to the Example Analysis page, where users can browse Jupyter notebook demos to explore previous data analyses on the HEAL platform.  </p> <p></p> <p>If your Browser does not support watching this video, here's a link to the video instead.  </p> <p>Currently available static Jupter Notebooks:</p> <p></p>"},{"location":"platform_example_analyses/#why-tutorial-notebooks","title":"Why tutorial Notebooks?","text":"<p>These notebooks will allow users to learn how to analyze and visualize data available on the HEAL platform - without having to take the additional steps of finding and exporting the data used by the tutorial first.</p> <p>All tutorial notebooks are static, view-only, and can be downloaded as <code>.html</code> files. Find the notebooks in interactive mode in the Workspace tab. Find below a description of how to work with the tutorials in the workspaces.  </p> <p>These tutorial notebooks are meant to:</p> <ul> <li>Give users a sense for how the platform can be used to analyze data.</li> <li>Bring complementary datasets together.</li> <li>Be used as a launching point for the users\u2019 own custom analysis.</li> <li>Spark imagination about how users can incorporate the platform data access, analysis, and collaboration tools into their own research and data analysis process and pipelines.</li> </ul> <p>The \u201cExample Analysis\u201d tab will be regularly updated with new and exciting tutorial data analysis notebooks, as more datasets are published and brought together in novel ways on the Platform.</p>"},{"location":"platform_example_analyses/#currently-available-notebooks","title":"Currently available Notebooks","text":"<p>Find below a list of notebooks that are currently available and which datasets they\u2019re based on.</p> <p>Click here to watch demo videos about how to use the tutorial Jupyter Notebooks as a launching point for your own custom analysis.</p> <p>Please link your account to all FAIR repositories before working with the Notebooks in interactive mode.</p> Notebook Name Project Title Project Number Datasets used Language BACPAC Synthetic Data Analysis Back Pain Consortium (BACPAC) Research Program Data Integration, Algorithm Development and Operations Management Center 1U24AR076730-01 1) participant_ SMART.tsv 2) substance_use_ SMART.tsv 3) physical_function_ SMART.tsv Python JCOIN Tracking Opioid Stigma Methodology and Advanced Analytics Resource Center 1U2CDA050098-01_a 1) JCOIN_NORC_ Omnibus_SURVEY1_ Feb2020.sav 2) JCOIN_NORC_ Omnibus_SURVEY2_ April2020.sav 3) JCOIN_NORC_ Omnibus_SURVEY3_ June2020.sav 4) JCOIN_NORC_ Omnibus_SURVEY4_ Oct2020.sav Python Opioid Prevalence And Overdoses 1) Drug Enforcement Administration Controlled Substances Tracking (DEA ARCOS)  2) Prescription Drug Abuse Policy System  2b) 3) CDC Wide-ranging Online Data for Epidemiologic Research (CDC WONDER) Mortality Multiple Cause-of-Death Public Use Record 1) deaarcos1  2) 57b45d83d6 c9e7e8693ccdfd  3) cdcwonder 1a) dea_arcos_drug_list.tsv 1b) dea_arcos_county_ population.tsv 1c) dea_arcos_combined_ county_annual.tsv 1d) dea_arcos_state_population.tsv  2a) 20170216-RM-Stat-Data.xlsx 2b) Naloxone_Data_09112020.xlsx 2c) 20180810_Good_Samaritan_ Law_Stat_Data.xlsx  3a) CDC_WONDER_unintentional_ overdoses.tsv 3b) CDC_WONDER_suicide_ overdoses.tsv 3c) monthly_unintentional_ overdoses.tsv Python Opioid Environment Toolkit and OEPS R (Watch tutorial) Methodology and Advanced Analytics Resource Center 1U2CDA050098-01_b 1) ZIP_COUNTY.xlsx 2) us-wide-moudsCleaned.csv 3) zctas2018.shp RStudio Opioid Overdose Trajectories (Watch tutorial) CDC Wide-ranging Online Data for Epidemiologic Research (CDC WONDER) Mortality Multiple Cause-of-Death Public Use Record cdcwonder 1) deaths_gender.xlsx 2) deaths_age_cat.xlsx 3) deaths_type_opioid.xlsx 4) cdc_wonder_year_cause_ hedegaard_et_al_2020.txt 5) cdc_wonder_year_cause_ state_hedegaard_et_al_2020.txt Python"},{"location":"platform_example_analyses/#working-with-the-tutorial-notebooks-in-interactive-mode","title":"Working with the Tutorial Notebooks in interactive mode","text":"<ul> <li> <p>Notebooks require linked access to all FAIR enabled repositories, as described here.</p> </li> <li> <p>Code in the notebooks is editable, and users can import additional datasets and extend their analysis.</p> </li> </ul>"},{"location":"platform_example_analyses/#demo-how-to-find-data-and-work-on-the-tutorial-notebooks","title":"Demo - How to find data and work on the Tutorial Notebooks","text":"<p>Below we describe the steps to export data from the Discovery Page tutorial Jupyter notebooks for one example tutorial notebook BACPAC_Synthetic_Data_Analysis.ipynb (\u201cBACPAC synthetic data analysis\u201d)</p> <p>Users must be logged in and have their accounts linked to the FAIR repositories in order to follow the steps below.</p> <ol> <li> <p>Go to the Workspace tab and click \u201cLaunch\u201d on the \u201cBACPAC Synthetic Data Analysis Notebook\u201d. This may take a few minutes to load.     Note, that depending on the chosen notebook, this step varies to align with the name of the notebook/workspace. </p> </li> <li> <p>Find and open the notebook in the landing directory by clicking on \u201cBACPAC_Synthetic_Data_Analysis.ipynb\". </p> </li> <li> <p>Click the first two cells and run them by clicking into the cell and either using shift+enter on the keyboard or selecting \u201cRun\u201d. Uncomment the commands as displayed below to install necessary packages. </p> </li> <li> <p>Run the next cell to import the data files. </p> </li> <li> <p>Explore the rest of the notebook. If you want to make changes, make sure to save the notebook as a new file in the directory \"pd\".  </p> </li> <li> <p>Make sure to terminate the workspace when the work is finished to reduce computational costs.</p> </li> </ol> <p>Note: Work must be saved in the directory \"/pd\" in order to remain accessible after workspace termination. Note, that Workspaces automatically shut down after 90 minutes of idle time.</p>"},{"location":"platform_profile_page/","title":"Profile Page","text":""},{"location":"platform_profile_page/#profile-page","title":"Profile Page","text":"<p>On the profile page users will find information regarding their access to projects, access to Gen3-specific tools (e.g. access to the /workspace), and the function to create API keys for credential downloads. API keys are necessary for the downloadof files using the Gen3-client; for more information see chapter 4.</p> <p></p> <p>Users can view their study access in the Profile Page.</p> <p></p> <p>API keys can be viewed, created, and downloaded on the Profile Page.</p>"},{"location":"platform_request_access/","title":"Access check/request","text":""},{"location":"platform_request_access/#check-and-request-access","title":"Check and request access","text":"<p>Users can find out for which studies they have access to data from the platform by navigating to the Discovery Page and selecting \u201cData Availability\" (#1), then \"Available\" (#2), then \u201dOK\u201d (#3), as shown below. Note: users should log in before they try to filter for studies with access to make sure that they are maximizing studies for which they have data access.  </p> <p></p> <p>If you also check the Request Access box, you will identify additional studies with data for which you can request access. (see our documentation about the Data Availability filter)</p>"},{"location":"platform_request_access/#access-to-individual-studies","title":"Access to individual Studies","text":"<p>You can also check access by clicking on a study in the Discovery Page (#1), then clicking on the Data tab in the study page (#2), as shown below.</p> <p></p> <p>The Data tab will display access permissions in the Data Files section. If you have access, a green box will show \u201cYou have access to this study\u201d.</p>"},{"location":"platform_request_access/#current-open-access-studies","title":"Current (open-access) studies","text":"<p>Current open-access studies will be shown when navigating to the Discovery Page. Users can download and/or export open-access study files after logging in. Currently, the HEAL Platform hosts the following studies. All are open-access except when noted.</p> <p>Note, that different studies relate to different Data Resources.</p> Project   number Study Name Data Resource 57b45d83d6c9e7e8693ccdfd Naloxone Overdose Prevention Laws PDAPS 10.3886/ICPSR34945.v3 National Mental Health Services   Survey (N-MHSS) ICPSR 1U24AR076730-01 A synthetic dataset from the Back   Pain Consortium (BACPAC) Research Program Data Integration, Algorithm   Development and Operations Management Center HEAL 10.3886/ICPSR04256.v5 National Survey of Substance Abuse   Treatment Services (N-SSATS) ICPSR cdcwonder CDC Wide-ranging Online Data for   Epidemiologic Research (CDC WONDER) Mortality Multiple Cause-of-Death Public   Use Record HEAL 10.3886/ICPSR30122.v5 Treatment Episode Data Set:   Discharges (TEDS-D) ICPSR deaarcos1 Drug Enforcement Administration   Controlled Substances Tracking (DEA ARCOS) HEAL a)   1U2CDA050098-01_a JCOIN - Methodology and Advanced   Analytics Resource Center: JCOIN b)   1U2CDA050098-01_b a) JCOIN 026: Amerispeak Brief   Stigma Survey JCOIN b) The Opioid Environment Policy   Scan JCOIN"},{"location":"platform_request_access/#overview-of-access-to-datasets-and-studies","title":"Overview of access to Datasets and Studies","text":"<p>Users can visit the \"Profile\u201d page to view a list of studies they have access to under the \u201cYou have access to the following project(s)\u201d section, as shown in the figure below.</p> <p></p> <p>A user can view their study access in the Profile Page.</p> <p>From here users can also view current API keys or create and download new keys. API keys are required for downloads which require use of the Gen3-client. More information in the chapter \u201cDownloading Data Files\u201d.</p> <p></p> <p>API keys can be viewed, created, and downloaded on the Profile Page.</p> <p>From here users can also view if they have access to projects or workspaces</p> <ul> <li>/dictionary_page: You have access to the data dictionary.</li> <li>/workspace: You have access to the workspace.</li> <li>/programs/open: You have access to open-access projects.</li> </ul>"},{"location":"platform_request_access/#linking-access-to-fair-enabled-repositories","title":"Linking access to FAIR enabled repositories","text":"<p>The HEAL Platform securely exposes data stored on multiple HEAL-compliant FAIR repositories.</p> <p>Users need to link their account to currently all FAIR repositories in order to:</p> <ol> <li>run Jupyter Notebooks that utilize data stored on various FAIR repositories.</li> <li>export data that are stored on FAIR repositories from the Discovery Page to the Workspaces.</li> <li>download data that are stored on FAIR repositories from the Discovery Page.</li> </ol> <p>In order to link the account to the involved FAIR repositories, navigate to the Profile Page and link the account to all current login options by clicking on the \"Refresh [..] Google Login\" buttons as shown below.</p> <p></p> <p>Linking access options on the Profile Page for data stored on FAIR enabled repositories.</p> <p>Access needs to be renewed after 30 days, as indicated after \"Status: expires in [..] days\".</p> <p>As a reminder, users will be prompted with a banner on the Workspace page and a pop-up window on the Discovery page.</p> <p></p> <p>Users are reminded on the Workspace page to link the account to all other FAIR enabled repositories on the Profile Page.</p> <p></p> <p>Users are reminded on the Discovery page to link the account to all other FAIR enabled repositories.</p>"},{"location":"platform_tutorial_videos/","title":"Tutorial Videos","text":""},{"location":"platform_tutorial_videos/#tutorial-videos","title":"Tutorial Videos","text":"<p>Watch our tutorial videos to learn how to interact with the HEAL Platform, export data files from the Discovery Page, and use the tutorial Jupyter Notebooks as a launching point for your own custom analysis.</p>"},{"location":"platform_tutorial_videos/#heal-platform-tutorial","title":"HEAL Platform Tutorial","text":"<p>Watch this video to start learning about all features on the HEAL Platform.  </p> <p></p> <p>If your Browser does not support watching this video, here's a link to the video instead.  </p>"},{"location":"platform_tutorial_videos/#the-opioid-environment-toolkit-and-oeps","title":"The Opioid Environment Toolkit and OEPS","text":"<p>This tutorial video demonstrates the use of the HEAL Platform Workspace through the analysis for the Opioid Environment Policy Scan Dataset using statistical tools written in the R programming language.  </p> <p></p> <p>If your Browser does not support watching this video, here's a link to the video instead.  </p>"},{"location":"platform_tutorial_videos/#opioid-overdose-trajectories","title":"Opioid Overdose Trajectories","text":"<p>This tutorial video demonstrates the use of the HEAL Platform to reproduce findings of a CDC study of Opioid Overdose Death rates in the United States.  </p> <p></p> <p>If your Browser does not support watching this video, here's a link to the video instead.  </p>"},{"location":"platform_tutorial_videos/#heal-example-analysis","title":"HEAL Example Analysis","text":"<p>This video introduces users to the Example Analysis page, where users can browse Jupyter notebook demos to explore previous data analyses on the HEAL platform.  </p> <p></p> <p>If your Browser does not support watching this video, here's a link to the video instead.  </p>"},{"location":"platform_workspaces/","title":"Workspaces","text":""},{"location":"platform_workspaces/#workspaces","title":"Workspaces","text":"<p>HEAL Platform workspaces are secure data analysis environments in the cloud that can access data from one or more data resources. Workspaces include Jupyter notebooks, Python, and RStudio by default but can be configured to host virtually any application, including analysis workflows, data processing pipelines, or data visualization apps. In order to launch a workspace, users will need to request a Gen3 workspace account at \"https://healportal.org/\". There are two methods to support workspaces: grant-funded accounts paid for by your institution (STRIDES grant) or a STRIDES credit account supported by the NIH initiative. Note, it may take several days for your account to be approved.</p> <p>New to Jupyter? Learn more about the popular tool for data scientists on Jupyter.org (disclaimer: CTDS is not responsible for the content).</p>"},{"location":"platform_workspaces/#guideline-to-get-started","title":"Guideline to get started","text":"<p>Info</p> <p>To use workspaces, you must first register for workspace access as described on the Workspace Registration page.</p> <ol> <li>After navigating to https://healdata.org/portal/workspace, users will discover a list of pre-configured virtual machine (VM) images, as shown below.  </li> </ol> <p></p> <p>Available workspaces on the HEAL Platform (top). Users may need to link their accounts from other repositories (bottom); click here to see how.</p> <ul> <li>(Generic) Jupyter Notebook with R kernel: Choose this VM if you are familiar with setting up Python- or R-based Notebooks, or if you just exported one or multiple studies from the Discovery Page and want to start your custom analysis.</li> <li>(Generic, User-licensed) Stata Notebook: Choose this VM if you are familiar with Stata-based data analysis. This notebook requires a Stata license.</li> <li>Tutorial Notebooks: Explore our Jupyter Notebook tutorials written in Python or RStudio, which pull data from various sources of the HEAL Data Ecosystem to leverage statistical programs and data analysis tools.  </li> </ul> <p>All interactive tutorial notebooks can be also found as static version on the Notebook Browser tab; read more in the section \"Example Analysis\".  </p> <p>Feel free to edit and experiment with this collection of notebooks. They are your personal copies!  </p> <ul> <li>Notebooks in Python: (1) BACPAC Synthetic Data Analysis, (2) JCOIN Tracking Opioid Stigma, (3) Opioid Overdose Trajectories, (4) Opioid Prevalence And Overdoses</li> <li> <p>Notebooks in RStudio: (1) Opioid Environment Toolkit and OEPS</p> </li> <li> <p>Click \u201cLaunch\u201d on any of the above workspace flavors to spin up a copy of that VM. Note: Launching the VM may take several minutes.  </p> </li> </ul> <p></p> <p>The status of launching the workspace is displayed after clicking on \u201cLaunch\u201d.</p> <ol> <li>After launching, the home folders are displayed, one of which is the user's persistent drive (\"pd\").  </li> </ol> <p> </p>  The /pd directory is a user\u2019s persistent drive.  <ol> <li>Select the /pd folder. Only files saved in the /pd directory will remain available after termination of a workspace session.  </li> </ol> <p> </p>  New files or licenses should be saved in the the /pd directory if users need to access them after restarting the workspaces.  <ul> <li>Attention: Any personal files in the folder \u201cdata\u201d will be lost. Personal files in the directory /pd will persist.  </li> <li>Do not save files in the \"data\" and \u201cdata/healdata.org\u201d folders.  </li> <li> <p>The folder \u201chealdata.org\u201d in the \u201cdata\u201d folder will host the data files you have exported from the Discovery Page.  </p> </li> <li> <p>Start a new notebook by clicking \u201cNew\u201d in the top right corner and choose between Python 3 or R Studio as the base programmatic language.  </p> </li> </ul> <p> </p>  Start a new notebook under \u201cNew\u201d.  <ol> <li>Experiment away! Code blocks are entered in cells, which can be executed individually or all at once. Code documentation and comments can also be entered in cells, and the cell type can be set to support Markdown.  </li> </ol> <p>Results, including plots, tables, and graphics, can be generated in the workspace and downloaded as files.  </p> <p>Users can import data files directly into the Notebook code after selecting files from the \"Discovery Page\". An example is shown below.  </p> <p> </p> <ol> <li>Do not forget to terminate your workspace once your work is finished to be mindful of the cost-intensive computational effort. Note, that Workspaces automatically shut down after 90 minutes of idle time. </li> </ol> <p> </p>  Do not forget to terminate your workspace once your work is finished. Unterminated workspaces continue to accrue computational costs. <p>Further reading: read more about how to download data files into the Workspaces here.</p>"},{"location":"platform_workspaces/#upload-save-and-download-filesnotebooks","title":"Upload, save, and download Files/Notebooks","text":"<p>Users can upload data files or Notebooks from the local machine to the home directory by clicking on \u201cUpload\u201d and access them in the Notebook (see below).</p> <p> </p>  Upload data files or Notebooks to the workspace by clicking on \u201cUpload\u201d in the top right corner. On the upload screen, find your text file (in this example, it is \"this\\_is\\_a\\_demo.txt\") to upload from your local computer.  <p>Then run in the cells, for example:  </p> <p>import os  import pandas as pd  os.chdir('/data')  demo_df = pd.read_csv('/this_is_a_demo.txt', sep='\\t')  demo_df.head()  </p> <p>Users can save the notebook by clicking \"File\" - \"Save as\", as shown below.</p> <p> </p>  Save the notebook under \u201cFile\u201d - \"Save as\".  <p>Users can download notebooks by clicking \"File\" - \"Download as\", as shown below.</p> <p> </p>  Download the notebook as \".ipynb\"."},{"location":"platform_workspaces/#environments-languages-and-tools","title":"Environments, Languages, and Tools","text":"<p>The following environments are available in the workspaces:</p> <ul> <li>Jupyter </li> <li>RStudio </li> </ul> <p>The following programmatic languages are available in Jupyter Notebooks:</p> <ul> <li>RStudio (read more)</li> <li>Python 3 (read more)</li> <li>Stata (read more)</li> </ul> <p>The following tools are available in Jupyter Notebooks:</p> <ul> <li>GitHub (read GitHub documentation)</li> </ul>"},{"location":"platform_workspaces/#python-3-and-rstudio-in-jupyter","title":"Python 3 and RStudio in Jupyter","text":"<p>Both Python 3 and RStudio are available in Jupyter Notebooks. Users can expect to be able to use typical Python or RStudio packages, such as PyPI or CRAN. For Python and RStudio, users can start a new notebook under \"New\", as shown below.</p> <p> </p>  Find Python 3 or RStudio when starting a new notebook under \u201cNew\u201d."},{"location":"platform_workspaces/#stata-in-jupyter","title":"Stata in Jupyter","text":"<p>Stata is available as language in Jupyter notebooks (either in Python or R kernels), but requires a license and a specific workspace.</p> <p>Users need to first choose the following workspace \"(Generic, User-licensed) Stata Notebook\" in order to be able to use Stata:</p> <p> </p>  Select this workspace to use Stata in the notebook.  <p>Users need to upload a license <code>stata.lic</code> to the /pd folder by selecting \"Upload\" (top right).</p> <p> </p>  If the upload was successful, the license appears in the directory /pd.  <p>Note, that uploading the license can also be achieved programmatically by opening a new terminal window under \"New\" - \"Terminal\", finding the directory /pd by typing: <code>cd pd</code> . Then, create a file using vim: <code>vim stata.lic</code> . This will open the file in the terminal. Users can copy the license, then hit <code>:</code> + <code>wq</code>.</p> <p>Then, users need to start a new notebook under \"New\" (choose either R or Python). Run the following code in the first cell:  </p> <p>import stata_setup stata_setup.config(\"/usr/local/stata17\", \"mp\")</p> <p>This will return the following:</p> <p> </p>  Setup the license in the first cell.  <p>Users can then begin using the notebook by typing in known Stata commands, for example <code>%% stata . describe</code> .</p>"},{"location":"platform_workspaces/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>If the kernel died, make sure to be logged in on 1) the Login Page 2) have enabled access to the FAIR enabled repository.</li> </ul>"},{"location":"platform_workspaces/#automatic-workspace-shutdown","title":"Automatic Workspace Shutdown","text":"<p>Workspaces automatically shut down after 90 minutes of idle time and a pop-up window will remind users before the workspace shuts down.</p> <p> </p>  A pop-up window will remind users to navigate back to the workspaces page in order to save the data.  <p>After the workspace has been shut down, users will be notified with the following pop-up window.</p> <p> </p>  Workspaces automatically shut down after 90 minutes of idle time."},{"location":"reporting-repo/","title":"Reporting Repository Selection and Data Availability","text":""},{"location":"reporting-repo/#reporting-repository-selection-and-data-availability","title":"Reporting Repository Selection and Data Availability","text":""},{"location":"reporting-repo/#selecting-a-heal-compliant-repository","title":"Selecting a HEAL-compliant repository","text":"<p>There are several considerations when selecting the best repository for your data. We encourage you to review the Repository Selection Guide to view the HEAL-compliant repositories and their features and characteristics. HEAL investigators can get assistance with selecting a repository by contacting the HEAL Data Stewards.</p>"},{"location":"reporting-repo/#how-can-i-tell-if-my-study-shows-a-repository-selection-on-the-platform","title":"How can I tell if my study shows a repository selection on the platform?","text":"<p>You can check the HEAL Data Platform to see if we have a data repository selection recorded for your study. </p> <ul> <li>Click on the Discovery button, or go to https://healdata.org/portal/discovery</li> <li>Search for your study (e.g., by project number, name, or PI)</li> <li>Find your study in the search results. At the bottom of the study row, there may be multiple color-bordered boxes. If we have your repo selection on the platform, it will appear in one of these boxes (generally the first, but does not have to be). The red arrow below shows an example of a study that selected Dryad as their repository. </li> </ul> <p></p>"},{"location":"reporting-repo/#my-study-doesnt-show-the-repository-i-selected-how-can-i-update-that","title":"My study doesn't show the repository I selected. How can I update that?","text":"<p>If you need to report the repository(ies) that you have selected, there are two options to do so:</p> <ol> <li> <p>If you have not yet registered your study:  </p> <p>You will have the option to indicate your repository selection when you register your study. You can follow the instructions here to register. If you have any trouble or questions, reach out to us at heal-support@datacommons.io.  </p> </li> <li> <p>If you have already registered your study, or you have more than one repository selection:</p> <p>You can email us at heal-support@datacommons.io to report your repository selection(s). In your email, please include the permalink to your study page on the platform. </p> </li> </ol>"},{"location":"reporting-repo/#get-the-permalink-to-your-study","title":"Get the permalink to your study","text":"<p>To get the permalink to your study, you can do the following:  </p> <ul> <li>Click on the Discovery button, or go to https://healdata.org/portal/discovery</li> <li>Search for your study (e.g., by project number, name, or PI)</li> <li>Click on the study in the search results</li> <li>In the window that opens with the study page details, there is a button in the upper right corner that says Permalink. Click the permalink button to copy the direct link to the study details page.  </li> </ul>"},{"location":"reporting-repo/#reporting-that-data-is-now-available","title":"Reporting that data is now available","text":"<p>If you have deposited your data in a HEAL-compliant repository, we want to link to your data from the HEAL Data Platform. Please email us at heal-support@datacommons.io to share your data link(s). In your email, please include the permalink to the platform study page (see above).  </p>"},{"location":"slmd_submission/","title":"Study-Level Metadata Submission","text":""},{"location":"slmd_submission/#study-level-metadata-submission","title":"Study-Level Metadata Submission","text":"<p>Info</p> <p>There is detailed guidance available for completing the CEDAR metadata form.</p> <p></p><p>CEDAR Form Guidance</p>"},{"location":"slmd_submission/#fill-out-your-cedar-form","title":"Fill out your CEDAR form","text":"<p>The act of submitting the study registration form will result in the creation of a metadata input form within your CEDAR account:</p> <ul> <li>Find the form for your study under the 'Shared with Me' folder on CEDAR   (accessible in the left-hand navigation).</li> <li>When you enter additional data into the CEDAR form, be sure to SAVE your   changes by scrolling to the bottom of the form.</li> <li>The HEAL Data Platform will pull entries from the CEDAR templates into the   Platform to enhance search capabilities and provide increasingly robust   study details.</li> </ul> <p>Watch our tutorial videos to learn how to interact with the CEDAR metadata forms and submit study-level metadata.</p>"},{"location":"slmd_submission/#why-metadata-are-important-finding-your-study-metadata-form","title":"Why Metadata are Important, &amp; Finding Your Study Metadata Form","text":"<p>This video covers:</p> <ul> <li>Why completing the metadata form is important</li> <li>How to find the metadata form</li> <li>How to share the metadata form</li> </ul> <p>Note</p> <p>This video is to be watched after you have registered your study with the Platform. If you have not yet registered your study, we have instructional videos to help you with this process.</p> <p></p> <p>Resources of interest mentioned in this video include:</p> <ul> <li>Fresh FAIR Webinar Series Video - Metadata 101</li> <li>Fresh FAIR Webinar Series Video - Metadata 102</li> <li>Other resources: healdatafair.org/resources/metadata</li> <li>Contact address for help: heal-support@datacommons.io</li> </ul> <p>You can also view this video on YouTube.</p>"},{"location":"slmd_submission/#completing-the-study-metadata-form","title":"Completing the Study Metadata Form","text":"<p>This video provides a step-by-step guide for completing the HEAL study-level metadata form.</p> <p></p> <p>Resources of interest mentioned in this video include:</p> <ul> <li>Other metadata resources: healdatafair.org/resources/metadata</li> <li>Contact address for help: heal-support@datacommons.io</li> </ul> <p>You can also view this video on YouTube.</p>"},{"location":"study-registration/","title":"Study Registration","text":""},{"location":"study-registration/#study-registration","title":"Study Registration","text":"<p>Registering Your Study</p> <p>Registering your study is a simple, three-step process:</p> <ol> <li>Request access to register your study.</li> <li>Create a CEDAR account, if you do not already have one.</li> <li>Register your study on the HEAL Data Platform. </li> </ol> <p>After completing registration, the next step will be completing your metadata form in CEDAR. </p> <p></p><p>How to request access</p>"},{"location":"study-registration/#overview","title":"Overview","text":"<p>The HEAL Data Platform provides a single interface where users can browse and search for all HEAL-funded studies as well as other HEAL-relevant datasets. In this way, the Platform plays a fundamental role in making HEAL data findable as part of adhering to the FAIR data principles (i.e., data should be Findable, Accessible, Interoperable and Reusable).</p> <p>To achieve this goal, the platform aggregates metadata about each study from multiple sources. One of these is NIH RePORTER from which basic information about all HEAL-funded studies is automatically obtained. However, there are three additional sources of metadata which the Platform can utilize:</p> <ul> <li>Information entered into the   Center for Expanded Data Annotation and Retrieval (CEDAR) Workbench,   an online platform for creating and managing metadata according to the FAIR   principles</li> <li>Information from ClinicalTrials.gov for   those clinical studies registered there</li> <li>Information from the data repository to which the study is submitting its   data</li> </ul> <p>To permit the Platform to pull information from these sources, a study must be registered. Registration is the process of linking a study to one or more of the metadata/data sources listed above. This process can be performed by the Principal Investigator or another member of the research team.</p> <p>What if I'm not ready to submit data yet?</p> <p>You may register your study at any time, even if you are not yet ready to submit data to a repository. Registering your study increases its visibility on the Platform and allows the Platform and data repository to anticipate and plan for your subsequent data submission.</p>"},{"location":"study-registration/registering-your-study/","title":"Registering Your Study","text":""},{"location":"study-registration/registering-your-study/#registering-your-study","title":"Registering Your Study","text":"<p>Info</p> <p>You must request access before you can register your study.</p> <p>Also, if you have not already done so, create an account with CEDAR (choose the \"Register\" option to quickly set up an account). You will need a CEDAR account to complete the registration process. Note that your CEDAR User UUID can be found at the top of your CEDAR profile page.</p> <p>Info</p> <p>This video highlights the next step in registering your study on the HEAL Data Platform. Registration with the HEAL Platform is necessary for compliance with the HEAL Data Sharing Policy. Written instructions are below. </p> <p></p> <p>Upon receiving notification that you\u2019ve been granted access to register your study, please proceed with the steps outlined below.</p>"},{"location":"study-registration/registering-your-study/#step-1-login-to-the-heal-data-platform","title":"Step 1:  Login to the HEAL Data Platform","text":""},{"location":"study-registration/registering-your-study/#step-2-find-your-study","title":"Step 2: Find your study","text":"<p>From the Discovery Page, find the study you wish to register:</p> <ul> <li>Click on the study to open the Study Page </li> <li>At the top of the Study Page, select \u2018Request Access to Register This Study\u2019   to navigate to the Study Registration form.</li> </ul>"},{"location":"study-registration/registering-your-study/#step-3-complete-the-study-registration-form","title":"Step 3:  Complete the Study Registration form","text":"<ul> <li>The <code>Study</code> field will already be filled in</li> <li>If known, a valid ClinicalTrials.gov ID (NCT #) can be entered, which will   enable the platform to pull some additional metadata related to the study.</li> <li>If known, select the repository you have submitted data to, or intend to   submit data to.  This will help the Platform us and the repository to which   you have submitted or will be submitting your data to anticipate and plan   accordingly.</li> <li>If your repository is not listed, please     contact us with those details.</li> <li>Enter the unique ID for your study within the repository.</li> <li>Submit your registration.</li> <li>After you successfully register your study, the study will disappear from the HEAL Data Platform for about 24 hours while we sync the study record with the new CEDAR form. You do not need to do anything for it to reappear. </li> </ul> <p>Alternate steps to register a study:</p> <ul> <li>Login to the Study Registration form</li> <li>Choose the study you wish to register from the Study dropdown.  Only those   studies you have been approved to register will be displayed in the dropdown.</li> <li>Complete the form as noted above and submit.</li> </ul> <p></p>"},{"location":"study-registration/registering-your-study/#next-steps-fill-out-your-cedar-form","title":"Next Steps: Fill out your CEDAR form","text":"<p>The act of submitting the study registration form will result in the creation of a metadata input form within your CEDAR account:</p> <ul> <li>Find the form for your study under the 'Shared with Me' folder on CEDAR   (accessible in the left-hand navigation).</li> <li>When you enter additional data into the CEDAR form, be sure to SAVE your   changes by scrolling to the bottom of the form.</li> <li>The HEAL Data Platform will pull entries from the CEDAR templates into the   Platform to enhance search capabilities and provide increasingly robust   study details.</li> <li>An overview of completing the CEDAR metadata form can be found here.</li> </ul>"},{"location":"study-registration/requesting-access/","title":"Requesting Access","text":""},{"location":"study-registration/requesting-access/#requesting-access","title":"Requesting Access","text":"<p>Info</p> <p>This video highlights the first step of registering your study on the HEAL Data Platform. Registration with the HEAL Platform is necessary for compliance with the HEAL Data Sharing Policy. Written instructions are below.</p> <p></p>"},{"location":"study-registration/requesting-access/#step-1-login-to-the-heal-data-platform","title":"Step 1: Login to the HEAL Data Platform","text":""},{"location":"study-registration/requesting-access/#step-2-find-your-study","title":"Step 2: Find your study","text":"<p>From the Discovery Page, find the study you wish to request access to register. (If you cannot find your study, contact us at heal-support@datacommons.io.)</p> <ul> <li>Click on the study to open the Study Page</li> <li>At the top of the Study Page, select <code>Request Access to Register This Study</code>   to navigate to the Study Registration Access Request form.</li> </ul> <p></p> <p>In cases where a study is represented by multiple records on the HEAL Data Platform but data and/or other digital artifacts will only be shared collectively (e.g., through a DCC or in the case of a study that has records from multiple years of funding and/or supplements but will be sharing data only through the parent award), it's likely not necessary that each grant be represented and registered as a stand-alone record on the Platform. If you would like to discuss the representation of your awards on the HEAL Data Platform, please contact us at heal-support@datacommons.io.</p>"},{"location":"study-registration/requesting-access/#step-3-complete-the-study-registration-access-request-form","title":"Step 3: Complete the Study Registration Access Request Form","text":"<ul> <li>The field <code>Study Name - Grant Number</code> will already be filled in.</li> <li>You will need to provide your name, your email address, institutional   affiliation and role on the project/study.</li> </ul> <p>After submitting, you will receive an email indicating the status of your request within one business day. When approved, you will then be able to register your study.</p>"},{"location":"vlmd/","title":"Variable-level Metadata Submission","text":""},{"location":"vlmd/#variable-level-metadata-submission","title":"Variable-level Metadata Submission","text":"<p>Data Dictionaries, which contain variable-level metadata, describe each variable within a dataset. Examples of variable-level attributes include the variable name, description (or variable label), type, format, terminology, and source.</p> <p>In order to submit a study\u2019s data dictionary to the Platform, the data dictionary must conform to the HEAL variable-level metadata schema. The following instructions will demonstrate how to use the HEAL Data Utilities' VLMD tool to help you generate a HEAL-compliant data dictionary from your dataset or existing data dictionary.</p> <ol> <li> <p>How to Generate a HEAL-compliant Data Dictionary</p> </li> <li> <p>How to Submit a HEAL-compliant Data Dictionary</p> </li> </ol> <p>Info</p> <p>Note: in order to submit a data dictionary to the Platform, the study must first be registered.</p> <p>If you have not done so, please see our instructions on how to register your study. </p> <p></p><p>How to Register Your Study</p>"},{"location":"vlmd/vlmd_healdata_utils/","title":"Generate a HEAL-compliant Data Dictionary","text":""},{"location":"vlmd/vlmd_healdata_utils/#generate-a-heal-compliant-data-dictionary","title":"Generate a HEAL-compliant Data Dictionary","text":"<p>Info</p> <p>The following instructions pertain to the stand-alone, executable version of the HEAL VLMD tool as well as the use of the VLMD tool in HEAL Workspaces. These two options are recommended for users who are unfamiliar with installing Python software and/or who want to generate VLMD documents in the quickest and easiest way possible. If you would like to install and integrate the VLMD tool into an existing, local pipeline, please see the HEAL Data Utilities on GitHub or PyPi for more information.</p> <p>The HEAL VLMD tool was created to help investigators generate HEAL-compliant variable-level metadata (VLMD) documents that may be uploaded to the HEAL Data Platform. This VLMD tool uses a command-line interface (CLI), is available within HEAL Data Platform Workspaces, and can be incorporated into existing pipelines in the form of a Python module. </p>"},{"location":"vlmd/vlmd_healdata_utils/#using-the-stand-alone-vlmd-tool","title":"Using the Stand-alone VLMD Tool","text":"<p>In an effort to further streamline the VLMD extraction process for researchers, we have developed a stand-alone executable version of the VLMD tool. </p> <p>Download the VLMD Tool</p> <p>You can download the latest version of the VLMD tool for your operating system (i.e., MacOS, Windows, Linux) from the NIH HEAL Initiative\u2019s GitHub repository:</p> <p></p><p>Download Latest Software Release</p> <p>Once you have downloaded the appropriate zip file, double-click the file to unzip the package. You should then see a file labeled <code>vlmd</code> or <code>vlmd.exe</code>, depending on your operating system and how it is configured. </p> <p>Double-clicking <code>vlmd</code> will then open your computer's command-line interface (CLI). Once the interface opens and the VLMD tool is loaded, you will be presented with four prompts: documentation, extract, start, and validate. </p> <p></p>"},{"location":"vlmd/vlmd_healdata_utils/#cli-commands","title":"CLI Commands","text":""},{"location":"vlmd/vlmd_healdata_utils/#extract","title":"extract","text":"<p>Extract the variable level metadata from an existing file with a specific type/format</p>"},{"location":"vlmd/vlmd_healdata_utils/#start","title":"start","text":"<p>Start a data dictionary from an empty template</p>"},{"location":"vlmd/vlmd_healdata_utils/#validate","title":"validate","text":"<p>Check (validate) an existing HEAL Data Dictionary file to see if it follows the HEAL specifications after filling out a template or further annotation after extracting from a different format.</p> <p>Info</p> <p>Typing the <code>documentation</code> command will launch the VLMD Data Dictionary definitions in the HEAL Data Utilities documentation.</p>"},{"location":"vlmd/vlmd_healdata_utils/#using-the-vlmd-tool-in-heal-workspaces-with-python","title":"Using the VLMD Tool in HEAL Workspaces with Python","text":"<p>The VLMD tool has also been preloaded into a HEAL workspace, so that you may use it there instead of downloading it to your local machine. To request access to a workspace, see instructions here.</p> <p>Once workspace access has been approved, select the (Generic) Jupyter Lab Notebook with R Kernel to get started using the VLMD tool. You can start by uploading your REDCap data dictionary or data file to the persistent drive (/pd). Any data not saved to the persistent drive will be lost when the workspace is terminated. For more information, please see our documentation on HEAL workspaces. </p> <p></p> <p>Info</p> <p>Files containing human subjects data must be de-identified before uploading them to a workspace, and the user is responsible for ensuring that he or she has permission to upload the data to the cloud. Workspaces are secure and any file(s) a user uploads are only accessible by that user.</p> <p>If you are extracting variable-level metadata from a dataset stored in a format that contains metadata (e.g., Stata, SAS or SPSS), our recommendation is to make a copy of the dataset in which all of the data (i.e., the actual observations) have been deleted, leaving only the variable names, formats, labels, etc. Many people are unaware that this is possible, but it makes a great way of sharing information about your dataset without sharing the data themselves. And it is easy to do.</p> <p>For example, in Stata, once you have a dataset loaded in memory all that is required is:</p> <pre><code>drop in 1/l\nsave empty_dataset\n</code></pre> <p>Similarily, in SAS:</p> <pre><code>data empty_dataset;\n    set original_dataset;\n    stop;\nrun;\n</code></pre> <p>where the <code>stop</code> statement stops SAS from processing any rows.</p> <p>In either case, this will leave you with an empty dataset containing all of the original variable-level metadata which you may safely upload to a workspace for use with the VLMD tool.</p> <p>After you\u2019ve launched the workspace and uploaded your data dictionary or data file, you can import the necessary functions. Below are examples of how to extract VLMD from an SPSS data file, create a new VLMD file from scratch, and validate an existing data dictionary in CSV and JSON formats, all within a workspace. </p>"},{"location":"vlmd/vlmd_healdata_utils/#python-functions","title":"Python Functions","text":"<p><code>extract</code> </p><pre><code>from healdata_utils import convert_to_vlmd\n\nconvert_to_vlmd(input_filepath=\"~/pd/myfile.sav\",inputtype=\"spss\")\n</code></pre> <p>Note</p> <p>Currently the python subcommand is <code>convert_to_vlmd</code> but will be changed to <code>extract_to_vlmd</code> to be consistent with CLI. <code>extract</code> was chosen to better reflect the functionality.</p> <p><code>start</code> </p><pre><code>from healdata_utils import write_vlmd_template\n\nwrite_vlmd_template(tmpdir.joinpath(\"heal.csv\"),numfields=10)\n</code></pre> <p><code>validate</code> </p><pre><code>from healdata_utils import validate_vlmd_csv,validate_vlmd_json\n\nvalidate_vlmd_csv(\"data/myhealcsvdd.csv\")\n\nvalidate_vlmd_json(\"data/myhealjsondd.json\")\n</code></pre>"},{"location":"vlmd/vlmd_healdata_utils/#input","title":"Input","text":"<p>There are many applications and software packages that are commonly used during the data collection and processing phases of studies. The HEAL VLMD tool accommodates several of these different input file formats. Please follow the links below if you would like to learn more:</p> <ul> <li>CSV datasets</li> <li>CSV (minimal) data dictionary</li> <li>SPSS datasets</li> <li>SAS datasets</li> <li>Stata datasets</li> <li>REDCap data dictionary</li> <li>Frictionless Table Schema</li> <li>Excel dataset</li> </ul>"},{"location":"vlmd/vlmd_healdata_utils/#output","title":"Output","text":"<p>VLMD extraction will result in a JSON and CSV version of the HEAL data dictionary in the output folder along with the validation reports in the <code>errors</code> folder. See below:</p>"},{"location":"vlmd/vlmd_healdata_utils/#errors","title":"Errors","text":""},{"location":"vlmd/vlmd_healdata_utils/#heal-csv-errorsjson","title":"heal-csv-errors.json","text":"<ul> <li>outputted validation report for table in csv file against frictionless schema</li> </ul> <p>If valid, this file will contain: </p><pre><code>{\n    \"valid\": true,\n    \"errors\": []\n}\n</code></pre>"},{"location":"vlmd/vlmd_healdata_utils/#heal-json-errorsjson","title":"heal-json-errors.json","text":"<ul> <li>outputted jsonschema validation report.</li> </ul> <p>If valid, this file will contain: </p><pre><code>{\n    \"valid\": true,\n    \"errors\": []\n}\n</code></pre> <p>If no <code>outputdir</code> specified, the resulting HEAL-compliant data dictionaries will be named:</p> <ul> <li><code>heal-csvtemplate-data-dictionary.csv</code>: This is the CSV data dictionary</li> <li><code>heal-jsontemplate-data-dictionary.json</code>: This is the JSON version of the data dictionary</li> </ul> <p>For more information on workflows, functions, and definitions, please see the HEAL Data Utilities Documentation. </p>"},{"location":"vlmd/vlmd_healdata_utils/#workflow-summary","title":"Workflow Summary","text":"<p>Typical workflows for creating a HEAL-compliant data dictionary include:</p> <ol> <li> <p>Create your data dictionary</p> <p>(a) Run the <code>vlmd extract</code> command (or <code>convert_to_vlmd</code> if in python) to generate a HEAL-compliant data dictionary via your desired input format </p> <p>(b) Run the <code>vlmd template</code> command to start from an empty template.</p> </li> <li> <p>Add/annotate with additional information in your preferred HEAL data dictionary format (either <code>json</code> or <code>csv</code>).</p> <ul> <li>To further annotate and use the data dictionary, see the variable-level metadata field property information below:<ul> <li><code>csv</code> data dictionary</li> <li><code>json</code> data dictionary</li> </ul> </li> </ul> </li> <li> <p>Run the <code>vlmd validate</code> command  with your HEAL data dictioanry as the input to validate.</p> </li> <li> <p>Repeat (2) and (3) until you are ready to submit. Please note, currently only <code>name</code> and <code>description</code> are required.</p> </li> </ol>"},{"location":"vlmd/vlmd_healdata_utils/#next-steps","title":"Next Steps","text":"<p>Once you\u2019ve created your HEAL-compliant data dictionary, you\u2019re now ready to submit your data dictionary to the Platform. Please see our instructions on submitting a data dictionary.</p> <ul> <li>How to Submit a Data Dictionary</li> </ul> <p>If you have need any help generating a HEAL-compliant data dictionary with the VMLD Tool, or have a general inquiry, please contact us at heal-support@datacommons.io</p>"},{"location":"vlmd/vlmd_submission/","title":"Submit a Data Dictionary","text":""},{"location":"vlmd/vlmd_submission/#submit-a-data-dictionary","title":"Submit a Data Dictionary","text":"<p>In order to submit a HEAL-compliant data dictionary and have it be associated with your study on the HEAL Data Platform, that study must first be registered. If you have not already registered your study, please see our instructions on study registration.</p> <p>If you were the team member to register your study, please skip ahead to our instructions on how to submit a data dictionary to the Platform. </p> <p>If your study was registered by another team member, you will first need to request access to submit a data dictionary. Please follow the instructions below. </p>"},{"location":"vlmd/vlmd_submission/#request-access-to-submit-a-data-dictionary","title":"Request Access to Submit a Data Dictionary","text":""},{"location":"vlmd/vlmd_submission/#login-to-the-heal-data-platform","title":"Login to the HEAL Data Platform","text":""},{"location":"vlmd/vlmd_submission/#find-your-study","title":"Find your study","text":"<p>From the Discovery Page, find the study you wish to request access to register.</p> <ul> <li>Click on the study to open the Study Page</li> <li>At the top of the Study Page, select <code>Request Access to Submit a Data Dictionary</code>   to navigate to the Study Registration Access Request form.</li> </ul> <p></p>"},{"location":"vlmd/vlmd_submission/#complete-the-data-dictionary-submission-request-form","title":"Complete the Data Dictionary Submission Request Form","text":"<ul> <li>The field <code>Study Name - Grant Number</code> will already be filled in.</li> <li>You will need to provide your name, your email address, institutional   affiliation and role on the project/study.</li> </ul> <p>After submitting, you will receive an email indicating the status of your request within one business day. When approved, you will then be able to submit a data dictionary to the Platform.</p>"},{"location":"vlmd/vlmd_submission/#submit-a-data-dictionary_1","title":"Submit a Data Dictionary","text":"<p>Info</p> <p>Data dictionaries must conform to the HEAL variable-level metadata schema. Please view our instructions on how to generate a HEAL-compliant data dictionary if you have not yet done so. </p> <p></p><p>Generate a HEAL-compliant Data Dictionary</p> <p>Additionally, submissions should not include data of any kind. Submissions containing data will be removed from the Platform.</p> <p>More information and submission templates can be found here.</p>"},{"location":"vlmd/vlmd_submission/#login-to-the-heal-data-platform_1","title":"Login to the HEAL Data Platform","text":""},{"location":"vlmd/vlmd_submission/#find-your-study_1","title":"Find Your Study","text":"<p>From the Discovery Page, find the study for which you wish to submit a data dictionary. If you were not the member of your team to register the study, you will first need to request access to submit a data dictionary.</p> <ul> <li>Click on the study to open the Study Page </li> <li>At the top of the Study Page, select <code>\u2018Submit a Data Dictionary\u2019</code> to navigate to the Data Dictionary Submission Form.</li> </ul> <p>Info</p> <p>A study must be registered in order to submit a data dictionary. </p> <p>If you have not registered your study, please see our instructions on study registration</p> <p>If your study was registered by another team member, please see our instructions on requesting access to submit a data dictionary. </p>"},{"location":"vlmd/vlmd_submission/#complete-the-data-dictionary-submission-form","title":"Complete the Data Dictionary Submission Form","text":"<ul> <li>The <code>Study</code> field will already be filled in</li> <li>Choose the <code>Select File</code> button to browse your local computer for your data dictionary.</li> <li>Only TSV, CSV and JSON files can be submitted</li> <li>While multiple dictionaries can be associated with a study, the process currently supports one submission at a time. Please repeat this process for each data dictionary you wish to submit</li> <li>Submissions should not include data of any kind.  Submissions containing data will be removed from the Platform. </li> <li>Enter a unique name for your data dictionary.  This name will be used to identify the data dictionary for users on the Platform. </li> <li>Previously submitted data dictionary names are displayed, if applicable - using the same name for a new submission will overwrite the existing record.</li> <li>To facilitate processing of your submission, some administrative information is needed to allow HEAL Data Platform staff to contact you should the need arise:<ul> <li>First and Last name</li> <li>E-mail address</li> <li>Note that this information is not stored on the Platform, but is simply needed to support you throughout the submission process.</li> </ul> </li> <li>Submit your data dictionary</li> </ul>"},{"location":"vlmd/vlmd_submission/#processing-your-submission","title":"Processing Your Submission","text":"<p>Upon receipt of your successful submission, HEAL Data Platform staff will:</p> <ul> <li>Review your submission for compliance with the HEAL Data Platform variable-level metadata schema </li> <li>Ensure no data are included.  Files containing study-generated data of any kind will not be accepted.</li> <li>HEAL Data Platform staff will contact you with any questions and/or to work through any issues that may arise.  If there are no issues, you will be notified when processing is completed.</li> </ul>"},{"location":"vlmd/vlmd_submission/#additional-help","title":"Additional Help","text":"<p>More information about the HEAL variable-level metadata schema, as well as submission templates, can be found here.</p> <p>If you have issues with a submission, or have a general inquiry, please contact us at heal-support@datacommons.io.</p>"},{"location":"vlmd/schemas/csv-fields/","title":"HEAL Variable Level Metadata Fields","text":""},{"location":"vlmd/schemas/csv-fields/#heal-variable-level-metadata-fields","title":"HEAL Variable Level Metadata Fields","text":"<p>Variable level metadata individual fields integrated into the variable level metadata object within the HEAL platform metadata service.</p> <p>NOTE</p> <p>Only <code>name</code> and <code>description</code> properties are required.    For categorical variables, <code>constraints.enum</code> and <code>encodings</code> (where applicable) properties are highly encouraged.    For studies using HEAL or other common data elements (CDEs), <code>standardsMappings</code> information is highly encouraged.   <code>type</code> and <code>format</code> properties may be particularly useful for some variable types (e.g. date-like variables)</p>"},{"location":"vlmd/schemas/csv-fields/#properties","title":"Properties","text":"<p><code>module</code> (string)  The section, form, survey instrument, set of measures  or other broad category used  to group variables.</p> <p>Examples:</p> <pre><code>  Demographics\n</code></pre> <pre><code>  PROMIS\n</code></pre> <pre><code>  Substance use\n</code></pre> <pre><code>  Medical History\n</code></pre> <pre><code>  Sleep questions\n</code></pre> <pre><code>  Physical activity\n</code></pre> <p><code>name</code> (string,required)  The name of a variable (i.e., field) as it appears in the data. </p> <p><code>title</code> (string)  The human-readable title or label of the variable. </p> <p>Examples:</p> <pre><code>  My Variable\n</code></pre> <pre><code>  Gender identity\n</code></pre> <p><code>description</code> (string,required)  An extended description of the variable. This could be the definition of a variable or the  question text (e.g., if a survey). </p> <p>Examples:</p> <pre><code>  The participant's age at the time of study enrollment\n</code></pre> <pre><code>  What is the highest grade or level of school you have completed or the highest degree you have received?\n</code></pre> <p><code>type</code> (string)  A classification or category of a particular data element or property expected or allowed in the dataset.</p> <p>Definitions:</p> <ul> <li><code>number</code> (A numeric value with optional decimal places. (e.g., 3.14))</li> <li><code>integer</code> (A whole number without decimal places. (e.g., 42))</li> <li><code>string</code> (A sequence of characters. (e.g., \\\"test\\\"))</li> <li><code>any</code> (Any type of data is allowed. (e.g., true))</li> <li><code>boolean</code> (A binary value representing true or false. (e.g., true))</li> <li><code>date</code> (A specific calendar date. (e.g., \\\"2023-05-25\\\"))</li> <li><code>datetime</code> (A specific date and time, including timezone information. (e.g., \\\"2023-05-25T10:30:00Z\\\"))</li> <li><code>time</code> (A specific time of day. (e.g., \\\"10:30:00\\\"))</li> <li><code>year</code> (A specific year. (e.g., 2023)</li> <li><code>yearmonth</code> (A specific year and month. (e.g., \\\"2023-05\\\"))</li> <li><code>duration</code> (A length of time. (e.g., \\\"PT1H\\\")</li> <li><code>geopoint</code> (A pair of latitude and longitude coordinates. (e.g., [51.5074, -0.1278]))</li> </ul> <p>Possible values:</p> <ul> <li><code>number</code></li> <li><code>integer</code></li> <li><code>string</code></li> <li><code>any</code></li> <li><code>boolean</code></li> <li><code>date</code></li> <li><code>datetime</code></li> <li><code>time</code></li> <li><code>year</code></li> <li><code>yearmonth</code></li> <li><code>duration</code></li> <li><code>geopoint</code></li> </ul> <p><code>format</code> (string)  Indicates the format of the type specified in the <code>type</code> property.  Each format is dependent on the <code>type</code> specified.  For example: If <code>type</code> is \"string\", then see the String formats.  If <code>type</code> is \"date\", \"datetime\", or \"time\", default format is ISO8601 formatting for those respective types (see details on ISO8601 format for Date, Datetime,  or Time) - If you want to specify a date-like variable using standard Python/C strptime syntax, see here for details.  See here for more information about appropriate <code>format</code> values by variable <code>type</code>. </p> <p>[Additional information]</p> <p>Date Formats (date, datetime, time <code>type</code> variable):</p> <p>A format for a date variable (<code>date</code>,<code>time</code>,<code>datetime</code>). default: An ISO8601 format string. any: Any parsable representation of a date/time/datetime. The implementing library can attempt to parse the datetime via a range of strategies.</p> <p>{PATTERN}: The value can be parsed according to <code>{PATTERN}</code>, which <code>MUST</code> follow the date formatting syntax of  C / Python strftime such as:</p> <ul> <li><code>%Y-%m-%d</code> (for date, e.g., 2023-05-25)</li> <li><code>%Y%-%d</code> (for date, e.g., 20230525) for date without dashes</li> <li><code>%Y-%m-%dT%H:%M:%S</code> (for datetime, e.g., 2023-05-25T10:30:45)</li> <li><code>%Y-%m-%dT%H:%M:%SZ</code> (for datetime with UTC timezone, e.g., 2023-05-25T10:30:45Z)</li> <li><code>%Y-%m-%dT%H:%M:%S%z</code> (for datetime with timezone offset, e.g., 2023-05-25T10:30:45+0300)</li> <li><code>%Y-%m-%dT%H:%M</code> (for datetime without seconds, e.g., 2023-05-25T10:30)</li> <li><code>%Y-%m-%dT%H</code> (for datetime without minutes and seconds, e.g., 2023-05-25T10)</li> <li><code>%H:%M:%S</code> (for time, e.g., 10:30:45)</li> <li><code>%H:%M:%SZ</code> (for time with UTC timezone, e.g., 10:30:45Z)</li> <li><code>%H:%M:%S%z</code> (for time with timezone offset, e.g., 10:30:45+0300)</li> </ul> <p>String formats:</p> <ul> <li><code>email</code> if valid emails (e.g., test@gmail.com)</li> <li><code>uri</code> if valid uri addresses (e.g., https://example.com/resource123)</li> <li><code>binary</code> if a base64 binary encoded string (e.g., authentication token like aGVsbG8gd29ybGQ=)</li> <li><code>uuid</code> if a universal unique identifier also known as a guid (eg., f47ac10b-58cc-4372-a567-0e02b2c3d479)</li> </ul> <p>Geopoint formats:</p> <p>The two types of formats for <code>geopoint</code> (describing a geographic point).</p> <ul> <li><code>array</code> (if 'lat,long' (e.g., 36.63,-90.20))</li> <li><code>object</code> (if {'lat':36.63,'lon':-90.20})</li> </ul> <p><code>constraints.maxLength</code> (integer)  Indicates the maximum length of an iterable (e.g., array, string, or object). For example, if 'Hello World' is the longest value of a categorical variable, this would be a maxLength of 11.</p> <p><code>constraints.enum</code> (string)  Constrains possible values to a set of values.</p> <p>Examples:</p> <pre><code>  1|2|3|4|5|6|7|8\n</code></pre> <pre><code>  White|Black or African American|American Indian or Alaska Native|Native Hawaiian or Other Pacific Islander|Asian|Some other race|Multiracial\n</code></pre> <p><code>constraints.pattern</code> (string)  A regular expression pattern the data MUST conform to.</p> <p><code>constraints.maximum</code> (integer)  Specifies the maximum value of a field (e.g., maximum -- or most recent -- date, maximum integer etc). Note, this is different then maxLength property.</p> <p><code>constraints.minimum</code> (integer)  Specifies the minimum value of a field.</p> <p><code>encodings</code> (string)  Variable value encodings provide a way to further annotate any value within a any variable type, making values easier to understand. </p> <p>Many analytic software programs (e.g., SPSS,Stata, and SAS) use numerical encodings and some algorithms only support numerical values. Encodings (and mappings) allow categorical values to be stored as numerical values.</p> <p>Additionally, as another use case, this field provides a way to store categoricals that are stored as  \"short\" labels (such as abbreviations).</p> <p>Examples:</p> <pre><code>  0=No|1=Yes\n</code></pre> <pre><code>  HW=Hello world|GBW=Good bye world|HM=Hi,Mike\n</code></pre> <p><code>ordered</code> (boolean)  Indicates whether a categorical variable is ordered. This variable  is relevant for variables that have an ordered relationship but not necessarily  a numerical relationship (e.g., Strongly disagree &lt; Disagree &lt; Neutral &lt; Agree).</p> <p><code>missingValues</code> (string)  A list of missing values specific to a variable.</p> <p>Examples:</p> <pre><code>  Missing|Skipped|No preference\n</code></pre> <pre><code>  Missing\n</code></pre> <p><code>trueValues</code> (string)  For boolean (true) variable (as defined in type field), this field allows a physical string representation to be cast as true (increasing readability of the field). It can include one or more values.</p> <p>Examples:</p> <pre><code>  Required|REQUIRED\n</code></pre> <pre><code>  required|Yes|Y|Checked\n</code></pre> <pre><code>  Checked\n</code></pre> <pre><code>  Required\n</code></pre> <p><code>falseValues</code> (string)  For boolean (false) variable (as defined in type field), this field allows a physical string representation to be cast as false (increasing readability of the field) that is not a standard false value. It can include one or more values.</p> <p><code>repo_link</code> (string)  A link to the variable as it exists on the home repository, if applicable</p> <p><code>standardsMappings.url</code> (string)  The url that links out to the published, standardized mapping.</p> <p>Examples:</p> <pre><code>  https://cde.nlm.nih.gov/deView?tinyId=XyuSGdTTI\n</code></pre> <p><code>standardsMappings.type</code> (string)  The type of mapping linked to a published set of standard variables such as the NIH Common Data Elements program</p> <p>Examples:</p> <pre><code>  cde\n</code></pre> <pre><code>  ontology\n</code></pre> <pre><code>  reference_list\n</code></pre> <p><code>standardsMappings.label</code> (string)  A free text label of a mapping indicating a mapping(s) to a published set of standard variables such as the NIH Common Data Elements program.</p> <p>Examples:</p> <pre><code>  substance use\n</code></pre> <pre><code>  chemical compound\n</code></pre> <pre><code>  promis\n</code></pre> <p><code>standardsMappings.source</code> (string)  The source of the standardized variable.</p> <p>Examples:</p> <pre><code>  TBD (will have controlled vocabulary)\n</code></pre> <p><code>standardsMappings.id</code> (string)  The id locating the individual mapping within the given source.</p> <p><code>relatedConcepts.url</code> (string)  The url that links out to the published, standardized concept.</p> <p>Examples:</p> <pre><code>  https://cde.nlm.nih.gov/deView?tinyId=XyuSGdTTI\n</code></pre> <p><code>relatedConcepts.type</code> (string)  The type of mapping to a published set of concepts related to the given field such as  ontological information (eg., NCI thesaurus, bioportal etc)</p> <p><code>relatedConcepts.label</code> (string)  A free text label of mapping to a published set of concepts related to the given field such as  ontological information (eg., NCI thesaurus, bioportal etc)</p> <p><code>relatedConcepts.source</code> (string)  The source of the related concept.</p> <p>Examples:</p> <pre><code>  TBD (will have controlled vocabulary)\n</code></pre> <p><code>relatedConcepts.id</code> (string)  The id locating the individual mapping within the given source.</p> <p><code>univarStats.median</code> (number)</p> <p><code>univarStats.mean</code> (number)</p> <p><code>univarStats.std</code> (number)</p> <p><code>univarStats.min</code> (number)</p> <p><code>univarStats.max</code> (number)</p> <p><code>univarStats.mode</code> (number)</p> <p><code>univarStats.count</code> (integer)</p> <p><code>univarStats.twentyFifthPercentile</code> (number)</p> <p><code>univarStats.seventyFifthPercentile</code> (number)</p> <p><code>univarStats.categoricalMarginals.name</code> (string)</p> <p><code>univarStats.categoricalMarginals.count</code> (integer)</p>"},{"location":"vlmd/schemas/json-data-dictionary/","title":"Variable Level Metadata (Data Dictionaries)","text":""},{"location":"vlmd/schemas/json-data-dictionary/#variable-level-metadata-data-dictionaries","title":"Variable Level Metadata (Data Dictionaries)","text":"<p>This schema defines the variable level metadata for one data dictionary for a given study.Note a given study can have multiple data dictionaries</p>"},{"location":"vlmd/schemas/json-data-dictionary/#title-stringrequired","title":"<code>title</code> (string,required)","text":""},{"location":"vlmd/schemas/json-data-dictionary/#description-string","title":"<code>description</code> (string)","text":""},{"location":"vlmd/schemas/json-data-dictionary/#data_dictionary-arrayrequired","title":"<code>data_dictionary</code> (array,required)","text":"<p>Variable level metadata individual fields integrated into the variable level metadata object within the HEAL platform metadata service.</p> <p>NOTE</p> <p>Only <code>name</code> and <code>description</code> properties are required.    For categorical variables, <code>constraints.enum</code> and <code>encodings</code> (where applicable) properties are highly encouraged.    For studies using HEAL or other common data elements (CDEs), <code>standardsMappings</code> information is highly encouraged.   <code>type</code> and <code>format</code> properties may be particularly useful for some variable types (e.g. date-like variables)</p>"},{"location":"vlmd/schemas/json-data-dictionary/#properties-for-each-record","title":"Properties for each record","text":"<p><code>module</code> (string)  The section, form, survey instrument, set of measures  or other broad category used  to group variables.</p> <p>Examples:</p> <pre><code>  Demographics\n</code></pre> <pre><code>  PROMIS\n</code></pre> <pre><code>  Substance use\n</code></pre> <pre><code>  Medical History\n</code></pre> <pre><code>  Sleep questions\n</code></pre> <pre><code>  Physical activity\n</code></pre> <p><code>name</code> (string,required)  The name of a variable (i.e., field) as it appears in the data. </p> <p><code>title</code> (string)  The human-readable title or label of the variable. </p> <p>Examples:</p> <pre><code>  My Variable\n</code></pre> <pre><code>  Gender identity\n</code></pre> <p><code>description</code> (string,required)  An extended description of the variable. This could be the definition of a variable or the  question text (e.g., if a survey). </p> <p>Examples:</p> <pre><code>  The participant's age at the time of study enrollment\n</code></pre> <pre><code>  What is the highest grade or level of school you have completed or the highest degree you have received?\n</code></pre> <p><code>type</code> (string)  A classification or category of a particular data element or property expected or allowed in the dataset.</p> <p>Definitions:</p> <ul> <li><code>number</code> (A numeric value with optional decimal places. (e.g., 3.14))</li> <li><code>integer</code> (A whole number without decimal places. (e.g., 42))</li> <li><code>string</code> (A sequence of characters. (e.g., \"test\"))</li> <li><code>any</code> (Any type of data is allowed. (e.g., true))</li> <li><code>boolean</code> (A binary value representing true or false. (e.g., true))</li> <li><code>date</code> (A specific calendar date. (e.g., \"2023-05-25\"))</li> <li><code>datetime</code> (A specific date and time, including timezone information. (e.g., \"2023-05-25T10:30:00Z\"))</li> <li><code>time</code> (A specific time of day. (e.g., \"10:30:00\"))</li> <li><code>year</code> (A specific year. (e.g., 2023)</li> <li><code>yearmonth</code> (A specific year and month. (e.g., \"2023-05\"))</li> <li><code>duration</code> (A length of time. (e.g., \"PT1H\")</li> <li><code>geopoint</code> (A pair of latitude and longitude coordinates. (e.g., [51.5074, -0.1278]))</li> </ul> <p>Possible values:</p> <ul> <li><code>number</code></li> <li><code>integer</code></li> <li><code>string</code></li> <li><code>any</code></li> <li><code>boolean</code></li> <li><code>date</code></li> <li><code>datetime</code></li> <li><code>time</code></li> <li><code>year</code></li> <li><code>yearmonth</code></li> <li><code>duration</code></li> <li><code>geopoint</code></li> </ul> <p><code>format</code> (string)  Indicates the format of the type specified in the <code>type</code> property.  Each format is dependent on the <code>type</code> specified.  For example: If <code>type</code> is \"string\", then see the String formats.  If <code>type</code> is \"date\", \"datetime\", or \"time\", default format is ISO8601 formatting for those respective types (see details on ISO8601 format for Date, Datetime,  or Time) - If you want to specify a date-like variable using standard Python/C strptime syntax, see here for details.  See here for more information about appropriate <code>format</code> values by variable <code>type</code>. </p> <p>[Additional information]</p> <p>Date Formats (date, datetime, time <code>type</code> variable):</p> <p>A format for a date variable (<code>date</code>,<code>time</code>,<code>datetime</code>). default: An ISO8601 format string. any: Any parsable representation of a date/time/datetime. The implementing library can attempt to parse the datetime via a range of strategies.</p> <p>{PATTERN}: The value can be parsed according to <code>{PATTERN}</code>, which <code>MUST</code> follow the date formatting syntax of  C / Python strftime such as:</p> <ul> <li><code>%Y-%m-%d</code> (for date, e.g., 2023-05-25)</li> <li><code>%Y%-%d</code> (for date, e.g., 20230525) for date without dashes</li> <li><code>%Y-%m-%dT%H:%M:%S</code> (for datetime, e.g., 2023-05-25T10:30:45)</li> <li><code>%Y-%m-%dT%H:%M:%SZ</code> (for datetime with UTC timezone, e.g., 2023-05-25T10:30:45Z)</li> <li><code>%Y-%m-%dT%H:%M:%S%z</code> (for datetime with timezone offset, e.g., 2023-05-25T10:30:45+0300)</li> <li><code>%Y-%m-%dT%H:%M</code> (for datetime without seconds, e.g., 2023-05-25T10:30)</li> <li><code>%Y-%m-%dT%H</code> (for datetime without minutes and seconds, e.g., 2023-05-25T10)</li> <li><code>%H:%M:%S</code> (for time, e.g., 10:30:45)</li> <li><code>%H:%M:%SZ</code> (for time with UTC timezone, e.g., 10:30:45Z)</li> <li><code>%H:%M:%S%z</code> (for time with timezone offset, e.g., 10:30:45+0300)</li> </ul> <p>String formats:</p> <ul> <li><code>email</code> if valid emails (e.g., test@gmail.com)</li> <li><code>uri</code> if valid uri addresses (e.g., https://example.com/resource123)</li> <li><code>binary</code> if a base64 binary encoded string (e.g., authentication token like aGVsbG8gd29ybGQ=)</li> <li><code>uuid</code> if a universal unique identifier also known as a guid (eg., f47ac10b-58cc-4372-a567-0e02b2c3d479)</li> </ul> <p>Geopoint formats:</p> <p>The two types of formats for <code>geopoint</code> (describing a geographic point).</p> <ul> <li><code>array</code> (if 'lat,long' (e.g., 36.63,-90.20))</li> <li><code>object</code> (if {'lat':36.63,'lon':-90.20})</li> </ul> <p><code>constraints</code> (object)</p> <ul> <li> <p><code>maxLength</code> (integer)      Indicates the maximum length of an iterable (e.g., array, string, or     object). For example, if 'Hello World' is the longest value of a     categorical variable, this would be a maxLength of 11.</p> </li> <li> <p><code>enum</code> (array)      Constrains possible values to a set of values.</p> <p>Examples:</p> <pre><code>  [1, 2, 3, 4]\n</code></pre> <pre><code>  ['White', 'Black or African American', 'American Indian or Alaska Native', 'Native Hawaiian or Other Pacific Islander', 'Asian', 'Some other race', 'Multiracial']\n</code></pre> </li> <li> <p><code>pattern</code> (string)      A regular expression pattern the data MUST conform to.</p> </li> <li> <p><code>maximum</code> (integer)      Specifies the maximum value of a field (e.g., maximum -- or most     recent -- date, maximum integer etc). Note, this is different then     maxLength property.</p> </li> <li> <p><code>minimum</code> (integer)      Specifies the minimum value of a field.</p> </li> </ul> <p><code>encodings</code> (object)  Variable value encodings provide a way to further annotate any value within a any variable type, making values easier to understand. </p> <p>Many analytic software programs (e.g., SPSS,Stata, and SAS) use numerical encodings and some algorithms only support numerical values. Encodings (and mappings) allow categorical values to be stored as numerical values.</p> <p>Additionally, as another use case, this field provides a way to store categoricals that are stored as  \"short\" labels (such as abbreviations).</p> <p>Examples:</p> <pre><code>  {'0': 'No', '1': 'Yes'}\n</code></pre> <pre><code>  {'HW': 'Hello world', 'GBW': 'Good bye world', 'HM': 'Hi, Mike'}\n</code></pre> <p><code>ordered</code> (boolean)  Indicates whether a categorical variable is ordered. This variable  is relevant for variables that have an ordered relationship but not necessarily  a numerical relationship (e.g., Strongly disagree &lt; Disagree &lt; Neutral &lt; Agree).</p> <p><code>missingValues</code> (array)  A list of missing values specific to a variable.</p> <p>Examples:</p> <pre><code>  ['Missing', 'Skipped', 'No preference']\n</code></pre> <pre><code>  ['Missing']\n</code></pre> <p><code>trueValues</code> (array)  For boolean (true) variable (as defined in type field), this field allows a physical string representation to be cast as true (increasing readability of the field). It can include one or more values.</p> <p>Examples:</p> <pre><code>  ['required', 'Yes', 'Checked']\n</code></pre> <pre><code>  ['required']\n</code></pre> <p><code>falseValues</code> (array)  For boolean (false) variable (as defined in type field), this field allows a physical string representation to be cast as false (increasing readability of the field) that is not a standard false value. It can include one or more values.</p> <p><code>repo_link</code> (string)  A link to the variable as it exists on the home repository, if applicable</p> <p><code>standardsMappings</code> (array)  A published set of standard variables such as the NIH Common Data Elements program.</p> <p><code>relatedConcepts</code> (array)  Mappings to a published set of concepts related to the given field such as ontological information (eg., NCI thesaurus, bioportal etc)</p> <p><code>univarStats</code> (object)  Univariate statistics inferred from the data about the given variable </p> <ul> <li> <p><code>median</code> (number)</p> </li> <li> <p><code>mean</code> (number)</p> </li> <li> <p><code>std</code> (number)</p> </li> <li> <p><code>min</code> (number)</p> </li> <li> <p><code>max</code> (number)</p> </li> <li> <p><code>mode</code> (number)</p> </li> <li> <p><code>count</code> (integer)</p> </li> <li> <p><code>twentyFifthPercentile</code> (number)</p> </li> <li> <p><code>seventyFifthPercentile</code> (number)</p> </li> <li> <p><code>categoricalMarginals</code> (array)</p> </li> </ul>"},{"location":"workspaces/","title":"Workspace User Guide","text":""},{"location":"workspaces/#workspace-user-guide","title":"Workspace User Guide","text":"<p>Workspaces are secure data analysis environments in the cloud that can access data from one or more data resources in the HEAL Data Ecosystem. By default, workspaces on the HEAL Data Platform include Jupyter notebooks, Python and R, but can be configured to host virtually any application, including analysis workflows, data processing pipelines, or data visualization tools.</p> <p>New to Jupyter? Learn more about the popular tool for data scientists on Jupyter.org (disclaimer: CTDS is not responsible for the content).</p> <ol> <li>Register for Workspace Access on the HEAL Data Platform</li> <li>Getting Started with Workspaces on the HEAL Data Platform</li> </ol>"},{"location":"workspaces/heal_workspace_registration/","title":"Register for HEAL Data Platform Workspaces","text":""},{"location":"workspaces/heal_workspace_registration/#register-for-heal-data-platform-workspaces","title":"Register for HEAL Data Platform Workspaces","text":"<p>To start exploring workspaces on the HEAL Data Platform, users can apply for Temporary Trial Access. Extended access to workspaces on the HEAL Data Platform is granted using an NIH STRIDES workspace account, which can be requested after trial access is provisioned. Please see below for more details.</p>"},{"location":"workspaces/heal_workspace_registration/#guidelines-for-requesting-temporary-trial-access-to-heal-data-platform-workspaces","title":"Guidelines for Requesting Temporary Trial Access to HEAL Data Platform Workspaces","text":"<p>For new users without workspace access, please follow these steps:</p> <ol> <li> <p>Login to the HEAL Data Platform.   Please make a note of your specific login username; this is the username that will have access to workspaces.</p> </li> <li> <p>Click on the Workspace tab.        </p> <p>This opens the Workspace Access Request form</p> </li> <li> <p>Fill in the details and submit the form shown below.</p> <p></p> </li> <li> <p>The form should be completed only once. Following submission, users will see a success message and a link back to the Discovery page.</p> <p></p> <p>If you see any other message besides a success message, please reach out to us at heal-support@datacommons.io. We may not have received your access request.</p> </li> <li> <p>Users will receive another email notifying them the temporary trial access request has been approved. They should then be able to access workspaces on the HEAL Data Platform. Please note that the timeline for this approval can be a few business days. If you have not received a response after a few business days, please reach out to heal-support@datacommons.io to check the status of your access request.*</p> </li> </ol>"},{"location":"workspaces/heal_workspace_registration/#guidelines-for-requesting-extended-access-to-heal-data-platform-workspaces-using-strides","title":"Guidelines for Requesting Extended Access to HEAL Data Platform Workspaces using STRIDES","text":"<p>Please Note: The process for granting access for a workspace account through NIH STRIDES can take up to two weeks.</p> <p>The workspace account can be funded through NIH STRIDES (NIH Science and Technology Research Infrastructure for Discovery, Experimentation, and Sustainability). The NIH STRIDES Initiative allows NIH-funded researchers to explore the use of cloud environments to streamline NIH data use by partnering with commercial providers.</p> <p>By leveraging the STRIDES Initiative, NIH and NIH-funded institutions can begin to create a robust, interconnected ecosystem that breaks down silos related to generating, analyzing, and sharing research data.</p> <p>NIH-funded researchers with an active NIH award may take advantage of the STRIDES Initiative for their NIH-funded research projects. Eligible researchers include NIH intramural researchers and awardees of NIH contracts, other transaction agreements, grants, cooperative agreements, and other agreements. More information on NIH STRIDES and how to gain access can be found here. Please see below for registration steps</p> <ol> <li> <p>Users will receive an invitation via email to register for an NIH STRIDES workspace account. Users can click the link in the invitation email or request a workspace account by visiting https://healportal.org/ and logging in.         </p> </li> <li> <p>After authorization, users will be able to see active workspace accounts and credits.</p> <p>To request a workspace account, select \"Request New Workspace\" on the landing page.     </p> </li> <li> <p>Choose one of the two options a) STRIDES Grant/Award Funded or b) STRIDES Credits to request a workspace account.</p> <p></p> <p>For information on the NIH STRIDES options, please refer to the official page.</p> <ul> <li> <p>The STRIDES Grant/Award Funded form can be selected if researchers have received NIH funding (e.g. a grant, contract, cooperative agreement, or other transaction agreement) and intend to use these funds for a HEAL Data Platform Workspace account. With this option, the researchers' organization will be responsible for payment.</p> <p></p> </li> <li> <p>Select the STRIDES Credits form to request credits from the NIH STRIDES Initiative for the HEAL Data Platform Workspace account. With this option, once the request is approved, a new account with a spending limit of $XXX will be provisioned for usage.</p> <p></p> </li> </ul> </li> <li> <p>Submit the request. Note that the process of granting access for a workspace account can take up to two weeks and users will be notified. Following the approval, users will see the current workspace accounts and credits on the landing page.</p> </li> </ol>"},{"location":"workspaces/heal_workspaces/","title":"Using Workspaces on the HEAL Data Platform","text":""},{"location":"workspaces/heal_workspaces/#using-workspaces-on-the-heal-data-platform","title":"Using Workspaces on the HEAL Data Platform","text":"<p>Info</p> <p>To use workspaces, you must first register for workspace access as described on the Workspace Registration page.</p>"},{"location":"workspaces/heal_workspaces/#guidelines-to-get-started-in-workspaces","title":"Guidelines to get started in Workspaces","text":"<p>Once you have access to workspaces, use this guide below to get started with analysis work in workspaces.</p> <ol> <li> <p>Log in via https://healdata.org/portal/login to access workspaces.</p> </li> <li> <p>After navigating to https://healdata.org/portal/workspace, you will discover a list of pre-configured virtual machine (VM) images, as shown below.</p> <p></p> <ul> <li>(Generic) Jupyter Notebook with R kernel: Choose this VM if you are familiar with setting up Python- or R-based Notebooks, or if you just exported one or multiple studies from the Discovery Page and want to start your custom analysis.</li> <li>Tutorial Notebooks: Explore our Jupyter Notebook tutorials written in Python or R, which analyze data pulled from various sources on the HEAL Data Platform These are excellent resources for code to use to analyze data from HEAL, and examples that illustrate the variety of data and analyses available through HEAL.</li> </ul> </li> <li> <p>Click \u201cLaunch\u201d on any of the workspace options to spin up a copy of that VM. The status of launching the workspace is displayed after clicking on \u201cLaunch\u201d. Note: Launching the VM may take several minutes.</p> <p></p> </li> <li> <p>After launching, the home folder is displayed. One of these folders is your persistent drive (\"/pd\").</p> <p></p> </li> <li> <p>Select the /pd folder. New files or licenses should be saved in the the /pd directory if users need to access them after restarting the workspaces. Only files saved in the /pd directory will remain available after termination of a workspace session.</p> <p></p> <ul> <li>Attention: Any personal files in the folder \u201cdata\u201d will be lost. Personal files in the directory /pd will persist.</li> <li>Do not save files in the \"data\" or \u201cdata/healdata.org\u201d folders.</li> <li>The folder \u201chealdata.org\u201d in the \u201cdata\u201d folder will host the data files you have exported from the Discovery Page. Move these files to the /pd directory if you do not want to have to export them again.</li> <li>/pd has a capacity limit of 10GB.</li> </ul> </li> <li> <p>Start a new notebook under \u201cNotebook\u201d in the Launcher tab. Click the tiles in the launcher and choose between Python 3 or R Studio as the base programming language.</p> <p>Note: You can open and run multiple notebooks in your workspace; however, the generic, tutorial and nextflow workspace images are currently separate Docker images. There is no functionality to combine them or run nextflow in the Tutorial or Generic images. This may be available in the future, after further testing and development activities.</p> <p></p> </li> <li> <p>Experiment away! Code blocks are entered in cells, which can be executed individually or all at once. Code documentation and comments can also be entered in cells, and the cell type can be set to support Markdown.</p> <p>Results, including plots, tables, and graphics, can be generated in the workspace and downloaded as files.</p> </li> <li> <p>Do not forget to terminate your workspace when you are done with your session. Unterminated workspaces can continue to accrue computational costs. Note: workspaces automatically shut down after 90 minutes of idle time.</p> </li> </ol> <p></p> <p>Further reading: read more about how to download data files into the Workspaces here.</p>"},{"location":"workspaces/heal_workspaces/#upload-save-and-download-filesnotebooks","title":"Upload, Save, and Download Files/Notebooks","text":"<p>You can upload data files or Notebooks from your local machine to the home directory by clicking on \u201cUpload\u201d in the top left corner. Access the uploaded content in the Notebook (see below).</p> <p></p> <p>You can then save the notebook by clicking \"File\" - \"Save as\", as shown below.</p> <p></p> <p>You can then download notebooks by clicking \"File\" - \"Download\", as shown below. Download the notebook, for example, as \".ipynb\".</p> <p></p>"},{"location":"workspaces/heal_workspaces/#environments-languages-and-tools","title":"Environments, Languages, and Tools","text":"<p>The following environments are available in the workspaces:</p> <ul> <li>Jupyter Lab</li> </ul> <p></p> <p>The following programming languages are available in Jupyter Notebooks:</p> <ul> <li>R</li> <li>Python 3</li> </ul> <p>The following tools are available in Jupyter Notebooks:</p> <ul> <li>GitHub (read GitHub documentation)</li> </ul>"},{"location":"workspaces/heal_workspaces/#python-3-and-r-in-jupyter","title":"Python 3 and R in Jupyter","text":"<p>Both Python 3 and R are available in Jupyter Notebooks.</p> <p>Basic Python or R packages , such as PyPI or CRAN, as well as many tools typical for data analysis are already included in the base workspace images without further installation required. For Python and R, users can start a new notebook with one of the tiles under \"Notebook\", as shown below.</p> <p></p>"},{"location":"workspaces/heal_workspaces/#automatic-workspace-shutdown","title":"Automatic Workspace Shutdown","text":"<p>Warning: When a HEAL Workspace reaches the STRIDES Credits limit for STRIDES Credits Workspaces, or reaches the Hard Limit for STRIDES Grant Workspaces, the Workspace will be automatically terminated. Please be sure to save any work before reaching the STRIDES Credit or Hard Limit.</p> <p>Warning: Workspaces will also automatically shut down after 90 minutes of idle time. A pop-up window will remind users to navigate back to the workspaces page in order to save the data.</p> <p></p>"}]}